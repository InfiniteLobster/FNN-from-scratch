{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ada51c",
   "metadata": {},
   "source": [
    "This is jupyter notebook for test training runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb53da3",
   "metadata": {},
   "source": [
    "Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34519cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "#project code\n",
    "from FNN import FNN\n",
    "from OptimizersFunctions import *\n",
    "from ActivFunctions import  *\n",
    "from LossFunctions import *\n",
    "from SuppFunctions import *\n",
    "from TestingFunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3105b1c3",
   "metadata": {},
   "source": [
    "Tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2366984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to data\n",
    "path_data = \"data\\wdbc.data\"#data from https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b642e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNames = [\"ID number\",\"Diagnosis\",\"radius1\",\"texture1\",\"perimeter1\",\"area1\",\"smoothness1\",\"compactness1\",\"concavity1\",\"concave points1\",\"symmetry1\",\"fractal dimension1\",\"radius2\",\"texture2\",\"perimeter2\",\"area2\",\"smoothness2\",\"compactness2\",\"concavity2\",\"concave points2\",\"symmetry2\",\"fractal dimension2\",\"radius3\",\"texture3\",\"perimeter3\",\"area3\",\"smoothness3\",\"compactness3\",\"concavity3\",\"concave points3\",\"symmetry3\",\"fractal dimension3\"]\n",
    "#loading raw data \n",
    "data_raw = pd.read_csv(path_data,names = columnNames)\n",
    "data_NoId = data_raw.drop(columns=\"ID number\")#no need for id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0022fcb",
   "metadata": {},
   "source": [
    "Regression testing (on tabular data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1722e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting goal for analysis\n",
    "regGoal = \"radius1\"\n",
    "#setting general network hyperparameters'\n",
    "epochs = 1000\n",
    "batch_size = 12\n",
    "loss_derivative = MeanSquaredErrorDerivative\n",
    "size_test_set = 0.1\n",
    "#sgd specific\n",
    "learning_rate_sgd = 0.005\n",
    "grad_clip_sgd = 10\n",
    "#sgd_momentum specific\n",
    "learning_rate_sgd_momentum = 0.001\n",
    "grad_clip_sgd_momentum = 10\n",
    "momentum_sgd_momentum = 0.95\n",
    "#rmsprop specific\n",
    "learning_rate_rmsprop = 0.001\n",
    "grad_clip_rmsprop = 0\n",
    "#nag specific\n",
    "learning_rate_nag = 0.0005\n",
    "grad_clip_nag = 10\n",
    "momentum_nag = 0.6\n",
    "#adam specific\n",
    "learning_rate_adam = 0.005\n",
    "grad_clip_adam = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ee9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preparation for regression training\n",
    "data = data_NoId.drop(columns=\"Diagnosis\")#categorical variable is unneeded\n",
    "data = data.iloc[:,0:10]#using only mean features\n",
    "dataInput = data.drop(columns=regGoal).to_numpy()\n",
    "dataTarget = data.loc[:,regGoal].to_numpy()\n",
    "dataInput = dataInput.T\n",
    "dataTarget = dataTarget[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95272419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring network for regression task\n",
    "netReg = FNN([9,64, 32, 16, 8, 4, 2, 1],\n",
    "          [relu,identity],\n",
    "          method_ini=\"HeUni\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d801567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting data split\n",
    "n_samples = dataTarget.size\n",
    "indices = np.arange(0,n_samples)\n",
    "indices_test = np.random.permutation(round(n_samples*size_test_set))\n",
    "indices_train = list(set(indices) - set(indices_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac30d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting train set\n",
    "dataInput_train = dataInput[:,indices_train]\n",
    "dataTarget_train = dataTarget[:,indices_train]\n",
    "#getting test set\n",
    "dataInput_test = dataInput[:,indices_test]\n",
    "dataTarget_test = dataTarget[:,indices_test]\n",
    "#standarizing data\n",
    "meanDataInput_train = np.mean(dataInput_train, axis=1)\n",
    "meanDataInput_train = meanDataInput_train[:,np.newaxis]\n",
    "stdDataInput_train = np.std(dataInput_train, axis=1)\n",
    "stdDataInput_train = stdDataInput_train[:,np.newaxis]\n",
    "dataInput_train = (dataInput_train - meanDataInput_train) / stdDataInput_train\n",
    "dataInput_test =  (dataInput_test - meanDataInput_train) / stdDataInput_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c0d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models training (different optimizer)\n",
    "net_reg_sgd,_ = train_minibatch_sgd(copy.deepcopy(netReg), dataInput_train, dataTarget_train, epochs, learning_rate_sgd , batch_size, loss_derivative, grad_clip = grad_clip_sgd)\n",
    "net_reg_sgd_momentum,_ = train_minibatch_sgd_momentum(copy.deepcopy(netReg), dataInput_train, dataTarget_train, epochs, learning_rate_sgd_momentum, batch_size, loss_derivative, momentum = momentum_sgd_momentum, grad_clip = grad_clip_sgd_momentum)\n",
    "net_reg_rmsprop,_ = train_minibatch_rmsprop(copy.deepcopy(netReg), dataInput_train, dataTarget_train, epochs, learning_rate_rmsprop, batch_size, loss_derivative, grad_clip = grad_clip_rmsprop)\n",
    "net_reg_nag,_ = train_minibatch_nag(copy.deepcopy(netReg), dataInput_train, dataTarget_train, epochs, learning_rate_nag, batch_size, loss_derivative, momentum = momentum_nag, grad_clip = grad_clip_nag)\n",
    "net_reg_adam,_ = train_minibatch_adam(copy.deepcopy(netReg), dataInput_train, dataTarget_train, epochs, learning_rate_adam, batch_size, loss_derivative, grad_clip = grad_clip_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9280e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating error\n",
    "error_reg_sgd = MeanSquaredError(dataTarget_test,net_reg_sgd.predictRegression(dataInput_test))\n",
    "error_reg_momentum = MeanSquaredError(dataTarget_test,net_reg_sgd_momentum.predictRegression(dataInput_test))\n",
    "error_reg_rmsprop = MeanSquaredError(dataTarget_test,net_reg_rmsprop.predictRegression(dataInput_test))\n",
    "error_reg_nag = MeanSquaredError(dataTarget_test,net_reg_nag.predictRegression(dataInput_test))\n",
    "error_reg_adam = MeanSquaredError(dataTarget_test,net_reg_adam.predictRegression(dataInput_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ebb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing errors\n",
    "print(f\"Mean square error sgd: {error_reg_sgd}\")\n",
    "print(f\"Mean square error momentum: {error_reg_momentum}\")\n",
    "print(f\"Mean square error rmsprop: {error_reg_rmsprop}\")\n",
    "print(f\"Mean square error nag: {error_reg_nag}\")\n",
    "print(f\"Mean square error adam: {error_reg_adam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4677899",
   "metadata": {},
   "source": [
    "Binary classification testing (on tabular data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a85992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting general network hyperparameters'\n",
    "epochs = 1000\n",
    "batch_size = 12\n",
    "loss_derivative = BinaryCrossEntropyDerivative\n",
    "size_test_set = 0.1\n",
    "#sgd specific\n",
    "learning_rate_sgd = 0.005\n",
    "grad_clip_sgd = 10\n",
    "#sgd_momentum specific\n",
    "learning_rate_sgd_momentum = 0.001\n",
    "grad_clip_sgd_momentum = 10\n",
    "momentum_sgd_momentum = 0.95\n",
    "#rmsprop specific\n",
    "learning_rate_rmsprop = 0.001\n",
    "grad_clip_rmsprop = 0\n",
    "#nag specific\n",
    "learning_rate_nag = 0.0005\n",
    "grad_clip_nag = 10\n",
    "momentum_nag = 0.6\n",
    "#adam specific\n",
    "learning_rate_adam = 0.005\n",
    "grad_clip_adam = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3c6c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preparation for classification training\n",
    "dataClass = data_NoId\n",
    "dataInput= dataClass.iloc[:,1:].to_numpy()#all features without without diagn\n",
    "dataTarget_desc = dataClass.loc[:,\"Diagnosis\"].to_numpy()\n",
    "dataInput = dataInput.T\n",
    "dataTarget_desc = dataTarget_desc[np.newaxis,:]\n",
    "dataTarget_bin = np.zeros(dataTarget_desc.shape)\n",
    "dataTarget_bin[dataTarget_desc == \"M\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daff5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting data split\n",
    "n_samples = dataTarget_bin.size\n",
    "indices = np.arange(0,n_samples)\n",
    "indices_test = np.random.permutation(round(n_samples*0.2))\n",
    "indices_train = list(set(indices) - set(indices_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb053492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting train set\n",
    "dataInput_train = dataInput[:,indices_train]\n",
    "dataTarget_train = dataTarget_bin[:,indices_train]\n",
    "#getting test set\n",
    "dataInput_test = dataInput[:,indices_test]\n",
    "dataTarget_test = dataTarget_bin[:,indices_test]\n",
    "#standarizing data\n",
    "meanDataInput_train = np.mean(dataInput_train, axis=1)\n",
    "meanDataInput_train = meanDataInput_train[:,np.newaxis]\n",
    "stdDataInput_train = np.std(dataInput_train, axis=1)\n",
    "stdDataInput_train = stdDataInput_train[:,np.newaxis]\n",
    "dataInput_train = (dataInput_train - meanDataInput_train) / stdDataInput_train\n",
    "dataInput_test =  (dataInput_test - meanDataInput_train) / stdDataInput_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring network\n",
    "netClassBin = FNN([30,64, 32, 16, 8, 4, 2, 1],\n",
    "          [relu,sigmoid],\n",
    "          method_ini=\"HeNor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce334eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models training (different optimizer)\n",
    "net_classBin_sgd,_ = train_minibatch_sgd(copy.deepcopy(netClassBin), dataInput_train, dataTarget_train, epochs, learning_rate_sgd , batch_size, loss_derivative, grad_clip = grad_clip_sgd)\n",
    "net_classBin_sgd_momentum,_ = train_minibatch_sgd_momentum(copy.deepcopy(netClassBin), dataInput_train, dataTarget_train, epochs, learning_rate_sgd_momentum, batch_size, loss_derivative, momentum = momentum_sgd_momentum, grad_clip = grad_clip_sgd_momentum)\n",
    "net_classBin_rmsprop,_ = train_minibatch_rmsprop(copy.deepcopy(netClassBin), dataInput_train, dataTarget_train, epochs, learning_rate_rmsprop, batch_size, loss_derivative, grad_clip = grad_clip_rmsprop)\n",
    "net_classBin_nag,_ = train_minibatch_nag(copy.deepcopy(netClassBin), dataInput_train, dataTarget_train, epochs, learning_rate_nag, batch_size, loss_derivative, momentum = momentum_nag, grad_clip = grad_clip_nag)\n",
    "net_classBin_adam,_ = train_minibatch_adam(copy.deepcopy(netClassBin), dataInput_train, dataTarget_train, epochs, learning_rate_adam, batch_size, loss_derivative, grad_clip = grad_clip_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de605f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy calculation\n",
    "confMatComp_classBin_sgd = getConfMatCompBin(dataTarget_test,net_classBin_sgd.predictClassBinary(dataInput_test))\n",
    "confMatComp_classBin_sgd_momentum = getConfMatCompBin(dataTarget_test,net_classBin_sgd_momentum.predictClassBinary(dataInput_test))\n",
    "confMatComp_classBin_rmsprop = getConfMatCompBin(dataTarget_test,net_classBin_rmsprop.predictClassBinary(dataInput_test))\n",
    "confMatComp_classBin_nag = getConfMatCompBin(dataTarget_test,net_classBin_nag.predictClassBinary(dataInput_test))\n",
    "confMatComp_classBin_adam = getConfMatCompBin(dataTarget_test,net_classBin_adam.predictClassBinary(dataInput_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f72bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gettign clas names for visualization\n",
    "TAB_CLASSES = [\"Benign\",\"Malignant\"]\n",
    "#plotting confusion matrices\n",
    "plotConfMatBin(confMatComp_classBin_sgd,TAB_CLASSES,title=\"Test Confusion Matrix: sgd\")\n",
    "plotConfMatBin(confMatComp_classBin_sgd_momentum,TAB_CLASSES,title=\"Test Confusion Matrix: sgd_momentum\")\n",
    "plotConfMatBin(confMatComp_classBin_rmsprop,TAB_CLASSES,title=\"Test Confusion Matrix: rmsprop\")\n",
    "plotConfMatBin(confMatComp_classBin_nag,TAB_CLASSES,title=\"Test Confusion Matrix: nag\")\n",
    "plotConfMatBin(confMatComp_classBin_adam,TAB_CLASSES,title=\"Test Confusion Matrix: adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfeebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting accuracy\n",
    "accuracy_classBin_sgd = getAccuracyBin(confMatComp_classBin_sgd[0],confMatComp_classBin_sgd[1],confMatComp_classBin_sgd[2],confMatComp_classBin_sgd[3])\n",
    "accuracy_classBin_momentum = getAccuracyBin(confMatComp_classBin_sgd_momentum[0],confMatComp_classBin_sgd_momentum[1],confMatComp_classBin_sgd_momentum[2],confMatComp_classBin_sgd_momentum[3])\n",
    "accuracy_classBin_rmsprop = getAccuracyBin(confMatComp_classBin_rmsprop[0],confMatComp_classBin_rmsprop[1],confMatComp_classBin_rmsprop[2],confMatComp_classBin_rmsprop[3])\n",
    "accuracy_classBin_nag = getAccuracyBin(confMatComp_classBin_nag[0],confMatComp_classBin_nag[1],confMatComp_classBin_nag[2],confMatComp_classBin_nag[3])\n",
    "accuracy_classBin_adam = getAccuracyBin(confMatComp_classBin_adam[0],confMatComp_classBin_adam[1],confMatComp_classBin_adam[2],confMatComp_classBin_adam[3])\n",
    "#printing accuracy\n",
    "print(f\"Accuracy sgd: {accuracy_classBin_sgd}\")\n",
    "print(f\"Accuracy momentum: {accuracy_classBin_momentum}\")\n",
    "print(f\"Accuracy rmsprop: {accuracy_classBin_rmsprop}\")\n",
    "print(f\"Accuracy nag: {accuracy_classBin_nag}\")\n",
    "print(f\"Accuracy adam: {accuracy_classBin_adam}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17bfb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting Precision\n",
    "precision_classBin_sgd = getPrecisionBin(confMatComp_classBin_sgd[0],confMatComp_classBin_sgd[2])\n",
    "precision_classBin_momentum = getPrecisionBin(confMatComp_classBin_sgd_momentum[0],confMatComp_classBin_sgd_momentum[2])\n",
    "precision_classBin_rmsprop = getPrecisionBin(confMatComp_classBin_rmsprop[0],confMatComp_classBin_rmsprop[2])\n",
    "precision_classBin_nag = getPrecisionBin(confMatComp_classBin_nag[0],confMatComp_classBin_nag[2])\n",
    "precision_classBin_adam = getPrecisionBin(confMatComp_classBin_adam[0],confMatComp_classBin_adam[2])\n",
    "#printing Precision\n",
    "print(f\"Precision sgd: {precision_classBin_sgd}\")\n",
    "print(f\"Precision momentum: {precision_classBin_momentum}\")\n",
    "print(f\"Precision rmsprop: {precision_classBin_rmsprop}\")\n",
    "print(f\"Precision nag: {precision_classBin_nag}\")\n",
    "print(f\"Precision adam: {precision_classBin_adam}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6155dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting Recall\n",
    "recall_classBin_sgd = getRecallBin(confMatComp_classBin_sgd[0],confMatComp_classBin_sgd[3])\n",
    "recall_classBin_momentum = getRecallBin(confMatComp_classBin_sgd_momentum[0],confMatComp_classBin_sgd_momentum[3])\n",
    "recall_classBin_rmsprop = getRecallBin(confMatComp_classBin_rmsprop[0],confMatComp_classBin_rmsprop[3])\n",
    "recall_classBin_nag = getRecallBin(confMatComp_classBin_nag[0],confMatComp_classBin_nag[3])\n",
    "recall_classBin_adam = getRecallBin(confMatComp_classBin_adam[0],confMatComp_classBin_adam[3])\n",
    "#printing Recall\n",
    "print(f\"Recall sgd: {precision_classBin_sgd}\")\n",
    "print(f\"Recall momentum: {precision_classBin_momentum}\")\n",
    "print(f\"Recall rmsprop: {precision_classBin_rmsprop}\")\n",
    "print(f\"Recall nag: {precision_classBin_nag}\")\n",
    "print(f\"Recall adam: {precision_classBin_adam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e953c81d",
   "metadata": {},
   "source": [
    "Multi-class classification (on MNIST dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c50395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the data for multi class classification (no need to have data physically downloaded)\n",
    "import keras\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting general network hyperparameters'\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "loss_derivative = CrossEntropyDerivative\n",
    "size_test_set = 0.1\n",
    "#sgd specific\n",
    "learning_rate_sgd = 0.0001\n",
    "grad_clip_sgd = 10\n",
    "#sgd_momentum specific\n",
    "learning_rate_sgd_momentum = 0.0001\n",
    "grad_clip_sgd_momentum = 10\n",
    "momentum_sgd_momentum = 0.95\n",
    "#rmsprop specific\n",
    "learning_rate_rmsprop = 0.0001\n",
    "grad_clip_rmsprop = 0\n",
    "#nag specific\n",
    "learning_rate_nag = 0.0001\n",
    "grad_clip_nag = 10\n",
    "momentum_nag = 0.6\n",
    "#adam specific\n",
    "learning_rate_adam = 0.0001\n",
    "grad_clip_adam = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing dataset for training and testing\n",
    "x_train_flattened = x_train.reshape(x_train.shape[0],-1)\n",
    "x_test_flattened = x_test.reshape(x_test.shape[0],-1)\n",
    "y_train_flattened = y_train.reshape(-1)\n",
    "y_test_flattened = y_test.reshape(-1)\n",
    "#one_hot_encoding targets(y)\n",
    "dataTarget_train = one_hot_encode(y_train_flattened.T,10)\n",
    "dataTarget_test = one_hot_encode(y_test_flattened.T,10)\n",
    "#normalization(plus transpose to allign dataset to network architecture)\n",
    "dataInput_train = (x_train_flattened.T/255.0)\n",
    "dataInput_test =  (x_test_flattened.T/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d6cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring network\n",
    "netClassMulti = FNN([784,1024,512, 256, 128, 10],\n",
    "          [relu,softmax],\n",
    "          method_ini=\"HeNor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d8200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models training (different optimizer)\n",
    "net_classMulti_sgd,_ = train_minibatch_sgd(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_sgd , batch_size, loss_derivative, grad_clip = grad_clip_sgd)\n",
    "net_classMulti_sgd_momentum,_ = train_minibatch_sgd_momentum(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_sgd_momentum, batch_size, loss_derivative, momentum = momentum_sgd_momentum, grad_clip = grad_clip_sgd_momentum)\n",
    "net_classMulti_rmsprop,_ = train_minibatch_rmsprop(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_rmsprop, batch_size, loss_derivative, grad_clip = grad_clip_rmsprop)\n",
    "net_classMulti_nag,_ = train_minibatch_nag(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_nag, batch_size, loss_derivative,momentum = momentum_nag, grad_clip = grad_clip_nag)\n",
    "net_classMulti_adam,_ = train_minibatch_adam(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_adam, batch_size, loss_derivative, grad_clip = grad_clip_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c9bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting names of classes\n",
    "MNIST_CLASSES = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "#decoding test set\n",
    "dataTarget_test_decode = one_hot_decode(dataTarget_test)\n",
    "#getting predictions\n",
    "predi_classMulti_sgd = net_classMulti_sgd.predictClassMulti(dataInput_test)\n",
    "predi_classMulti_sgd_momentum = net_classMulti_sgd_momentum.predictClassMulti(dataInput_test)\n",
    "predi_classMulti_rmsprop = net_classMulti_rmsprop.predictClassMulti(dataInput_test)\n",
    "predi_classMulti_nag = net_classMulti_nag.predictClassMulti(dataInput_test)\n",
    "predi_classMulti_adam = net_classMulti_adam.predictClassMulti(dataInput_test)\n",
    "#getting confusion matrices\n",
    "cm_classMulti_sgd = getConfMatCompMulti(dataTarget_test_decode, predi_classMulti_sgd)\n",
    "cm_classMulti_sgd_momentum = getConfMatCompMulti(dataTarget_test_decode, predi_classMulti_sgd_momentum)\n",
    "cm_classMulti_rmsprop = getConfMatCompMulti(dataTarget_test_decode, predi_classMulti_rmsprop)\n",
    "cm_classMulti_nag = getConfMatCompMulti(dataTarget_test_decode, predi_classMulti_nag)\n",
    "cm_classMulti_adam = getConfMatCompMulti(dataTarget_test_decode, predi_classMulti_adam)\n",
    "#plotting confusion matrices\n",
    "plot_confusion_matrix(cm_classMulti_sgd, MNIST_CLASSES, title=\"Test Confusion Matrix: sgd\")\n",
    "plot_confusion_matrix(cm_classMulti_sgd_momentum, MNIST_CLASSES, title=\"Test Confusion Matrix: sgd_momentum\")\n",
    "plot_confusion_matrix(cm_classMulti_rmsprop, MNIST_CLASSES, title=\"Test Confusion Matrix: rmsprop\")\n",
    "plot_confusion_matrix(cm_classMulti_nag, MNIST_CLASSES, title=\"Test Confusion Matrix: nag\")\n",
    "plot_confusion_matrix(cm_classMulti_adam, MNIST_CLASSES, title=\"Test Confusion Matrix: adam\")\n",
    "#accuracy calculation\n",
    "accuracy_classMulti_sgd = getAccuracy(dataTarget_test_decode,predi_classMulti_sgd)\n",
    "accuracy_classMulti_momentum = getAccuracy(dataTarget_test_decode,predi_classMulti_sgd_momentum)\n",
    "accuracy_classMulti_rmsprop = getAccuracy(dataTarget_test_decode,predi_classMulti_rmsprop)\n",
    "accuracy_classMulti_nag = getAccuracy(dataTarget_test_decode,predi_classMulti_nag)\n",
    "accuracy_classMulti_adam = getAccuracy(dataTarget_test_decode,predi_classMulti_adam)\n",
    "#printing accuracy\n",
    "print(f\"Accuracy sgd: {accuracy_classMulti_sgd}\")\n",
    "print(f\"Accuracy momentum: {accuracy_classMulti_momentum}\")\n",
    "print(f\"Accuracy rmsprop: {accuracy_classMulti_rmsprop}\")\n",
    "print(f\"Accuracy nag: {accuracy_classMulti_nag}\")\n",
    "print(f\"Accuracy adam: {accuracy_classMulti_adam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4473b25",
   "metadata": {},
   "source": [
    "Multi-class classification (on CIFAR-10 dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c17a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting CIFAR-10 dataset (no need to have data physically downloaded)\n",
    "import keras\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8349fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting general network hyperparameters'\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "loss_derivative = SoftmaxCrossEntropyDerivative\n",
    "size_test_set = 0.1\n",
    "#sgd specific\n",
    "learning_rate_sgd = 0.0001\n",
    "grad_clip_sgd = 10\n",
    "#sgd_momentum specific\n",
    "learning_rate_sgd_momentum = 0.0001\n",
    "grad_clip_sgd_momentum = 10\n",
    "momentum_sgd_momentum = 0.95\n",
    "#rmsprop specific\n",
    "learning_rate_rmsprop = 0.0001\n",
    "grad_clip_rmsprop = 0\n",
    "#nag specific\n",
    "learning_rate_nag = 0.0001\n",
    "grad_clip_nag = 10\n",
    "momentum_nag = 0.6\n",
    "#adam specific\n",
    "learning_rate_adam = 0.0001\n",
    "grad_clip_adam = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbd9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing dataset for training and testing\n",
    "x_train_flattened = x_train.reshape(x_train.shape[0],-1)\n",
    "x_test_flattened = x_test.reshape(x_test.shape[0],-1)\n",
    "y_train_flattened = y_train.reshape(-1)\n",
    "y_test_flattened = y_test.reshape(-1)\n",
    "#one_hot_encoding targets(y)\n",
    "dataTarget_train = one_hot_encode(y_train_flattened.T,10)\n",
    "dataTarget_test = one_hot_encode(y_test_flattened.T,10)\n",
    "#normalization(plus transpose to allign dataset to network architecture)\n",
    "dataInput_train = (x_train_flattened.T/255.0)\n",
    "dataInput_test =  (x_test_flattened.T/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ad376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring network\n",
    "netClassMulti = FNN([3072,1024,512, 256, 128, 10],\n",
    "          [relu,softmax],\n",
    "          method_ini=\"HeNor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f790cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models training (different optimizer)\n",
    "net_classMulti_sgd,_ = train_minibatch_sgd(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_sgd , batch_size, loss_derivative, grad_clip = grad_clip_sgd)\n",
    "net_classMulti_sgd_momentum,_ = train_minibatch_sgd_momentum(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_sgd_momentum, batch_size, loss_derivative, momentum = momentum_sgd_momentum, grad_clip = grad_clip_sgd_momentum)\n",
    "net_classMulti_rmsprop,_ = train_minibatch_rmsprop(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_rmsprop, batch_size, loss_derivative, grad_clip = grad_clip_rmsprop)\n",
    "net_classMulti_nag,_ = train_minibatch_nag(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_nag, batch_size, loss_derivative, momentum = momentum_nag, grad_clip = grad_clip_nag)\n",
    "net_classMulti_adam,_ = train_minibatch_adam(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_adam, batch_size, loss_derivative, grad_clip = grad_clip_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615e7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting names of classes\n",
    "MNIST_CLASSES = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"] \n",
    "#decoding test set\n",
    "dataTarget_test_decode = one_hot_decode(dataTarget_test)\n",
    "#getting predictions\n",
    "predi_classMulti_sgd = net_classMulti_sgd.predictClassMulti(dataInput_test)\n",
    "predi_classMulti_sgd_momentum = net_classMulti_sgd_momentum.predictClassMulti(dataInput_test)\n",
    "predi_classMulti_rmsprop = net_classMulti_rmsprop.predictClassMulti(dataInput_test)\n",
    "predi_classMulti_nag = net_classMulti_nag.predictClassMulti(dataInput_test)\n",
    "predi_classMulti_adam = net_classMulti_adam.predictClassMulti(dataInput_test)\n",
    "#getting confusion matrices\n",
    "cm_classMulti_sgd = getConfMatCompMulti(dataTarget_test_decode, predi_classMulti_sgd, num_classes=10)\n",
    "cm_classMulti_sgd_momentum = getConfMatCompMulti(dataTarget_test_decode, predi_classMulti_sgd_momentum, num_classes=10)\n",
    "cm_classMulti_rmsprop = getConfMatCompMulti(dataTarget_test_decode, predi_classMulti_rmsprop, num_classes=10)\n",
    "cm_classMulti_nag = getConfMatCompMulti(dataTarget_test_decode, predi_classMulti_nag, num_classes=10)\n",
    "cm_classMulti_adam = getConfMatCompMulti(dataTarget_test_decode, predi_classMulti_adam, num_classes=10)\n",
    "#plotting confusion matrices\n",
    "plot_confusion_matrix(cm_classMulti_sgd, MNIST_CLASSES, title=\"Test Confusion Matrix: sgd\")\n",
    "plot_confusion_matrix(cm_classMulti_sgd_momentum, MNIST_CLASSES, title=\"Test Confusion Matrix: sgd_momentum\")\n",
    "plot_confusion_matrix(cm_classMulti_rmsprop, MNIST_CLASSES, title=\"Test Confusion Matrix: rmsprop\")\n",
    "plot_confusion_matrix(cm_classMulti_nag, MNIST_CLASSES, title=\"Test Confusion Matrix: nag\")\n",
    "plot_confusion_matrix(cm_classMulti_adam, MNIST_CLASSES, title=\"Test Confusion Matrix: adam\")\n",
    "#accuracy calculation\n",
    "accuracy_classMulti_sgd = getAccuracy(dataTarget_test_decode,predi_classMulti_sgd)\n",
    "accuracy_classMulti_momentum = getAccuracy(dataTarget_test_decode,predi_classMulti_sgd_momentum)\n",
    "accuracy_classMulti_rmsprop = getAccuracy(dataTarget_test_decode,predi_classMulti_rmsprop)\n",
    "accuracy_classMulti_nag = getAccuracy(dataTarget_test_decode,predi_classMulti_nag)\n",
    "accuracy_classMulti_adam = getAccuracy(dataTarget_test_decode,predi_classMulti_adam)\n",
    "#printing accuracy\n",
    "print(f\"Accuracy sgd: {accuracy_classMulti_sgd}\")\n",
    "print(f\"Accuracy momentum: {accuracy_classMulti_momentum}\")\n",
    "print(f\"Accuracy rmsprop: {accuracy_classMulti_rmsprop}\")\n",
    "print(f\"Accuracy nag: {accuracy_classMulti_nag}\")\n",
    "print(f\"Accuracy adam: {accuracy_classMulti_adam}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trying",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
