{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ada51c",
   "metadata": {},
   "source": [
    "This is jupyter notebook for test training runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb53da3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34519cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#general libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "#project code\n",
    "from FNN import FNN\n",
    "from gradient_descent import *\n",
    "from ActivFunctions import  *\n",
    "from LossFunctions import *\n",
    "from SuppFunctions import *\n",
    "from TestingFunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3105b1c3",
   "metadata": {},
   "source": [
    "Tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2366984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to data\n",
    "path_data = \"data\\wdbc.data\"#data from https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b642e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNames = [\"ID number\",\"Diagnosis\",\"radius1\",\"texture1\",\"perimeter1\",\"area1\",\"smoothness1\",\"compactness1\",\"concavity1\",\"concave points1\",\"symmetry1\",\"fractal dimension1\",\"radius2\",\"texture2\",\"perimeter2\",\"area2\",\"smoothness2\",\"compactness2\",\"concavity2\",\"concave points2\",\"symmetry2\",\"fractal dimension2\",\"radius3\",\"texture3\",\"perimeter3\",\"area3\",\"smoothness3\",\"compactness3\",\"concavity3\",\"concave points3\",\"symmetry3\",\"fractal dimension3\"]\n",
    "#loading raw data \n",
    "data_raw = pd.read_csv(path_data,names = columnNames)\n",
    "data_NoId = data_raw.drop(columns=\"ID number\")#no need for id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0022fcb",
   "metadata": {},
   "source": [
    "Regression testing (on tabular data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1722e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting goal for analysis\n",
    "regGoal = \"radius1\"\n",
    "#setting general network hyperparameters'\n",
    "epochs = 1000\n",
    "batch_size = 12\n",
    "loss_derivative = CrossEntropyDerivative\n",
    "size_test_set = 0.1\n",
    "#sgd specific\n",
    "learning_rate_sgd = 0.005\n",
    "grad_clip_sgd = 10\n",
    "#sgd_momentum specific\n",
    "learning_rate_sgd_momentum = 0.001\n",
    "grad_clip_sgd_momentum = 10\n",
    "momentum_sgd_momentum = 0.95\n",
    "#rmsprop specific\n",
    "learning_rate_rmsprop = 0.001\n",
    "grad_clip_rmsprop = 0\n",
    "#nag specific\n",
    "learning_rate_nag = 0.0005\n",
    "grad_clip_nag = 10\n",
    "momentum_nag = 0.6\n",
    "#adam specific\n",
    "learning_rate_adam = 0.005\n",
    "grad_clip_adam = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32ee9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preparation for regression training\n",
    "data = data_NoId.drop(columns=\"Diagnosis\")#categorical variable is unneeded\n",
    "data = data.iloc[:,0:10]#using only mean features\n",
    "dataInput = data.drop(columns=regGoal).to_numpy()\n",
    "dataTarget = data.loc[:,regGoal].to_numpy()\n",
    "dataInput = dataInput.T\n",
    "dataTarget = dataTarget[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95272419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring network for regression task\n",
    "netReg = FNN([9,64, 32, 16, 8, 4, 2, 1],\n",
    "          [relu,identity],\n",
    "          method_ini=\"HeUni\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d801567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting data split\n",
    "n_samples = dataTarget.size\n",
    "indices = np.arange(0,n_samples)\n",
    "indices_test = np.random.permutation(round(n_samples*size_test_set))\n",
    "indices_train = list(set(indices) - set(indices_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac30d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting train set\n",
    "dataInput_train = dataInput[:,indices_train]\n",
    "dataTarget_train = dataTarget[:,indices_train]\n",
    "#getting test set\n",
    "dataInput_test = dataInput[:,indices_test]\n",
    "dataTarget_test = dataTarget[:,indices_test]\n",
    "#standarizing data\n",
    "meanDataInput_train = np.mean(dataInput_train, axis=1)\n",
    "meanDataInput_train = meanDataInput_train[:,np.newaxis]\n",
    "stdDataInput_train = np.std(dataInput_train, axis=1)\n",
    "stdDataInput_train = stdDataInput_train[:,np.newaxis]\n",
    "dataInput_train = (dataInput_train - meanDataInput_train) / stdDataInput_train\n",
    "dataInput_test =  (dataInput_test - meanDataInput_train) / stdDataInput_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59c0d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models training (different optimizer)\n",
    "net_reg_sgd = train_minibatch_sgd(copy.deepcopy(netReg), dataInput_train, dataTarget_train, epochs, learning_rate_sgd , batch_size, loss_derivative, grad_clip = grad_clip_sgd)\n",
    "net_reg_sgd_momentum = train_minibatch_sgd_momentum(copy.deepcopy(netReg), dataInput_train, dataTarget_train, epochs, learning_rate_sgd_momentum, batch_size, loss_derivative, momentum = momentum_sgd_momentum, grad_clip = grad_clip_sgd_momentum)\n",
    "net_reg_rmsprop = train_minibatch_rmsprop(copy.deepcopy(netReg), dataInput_train, dataTarget_train, epochs, learning_rate_rmsprop, batch_size, loss_derivative, grad_clip = grad_clip_rmsprop)\n",
    "net_reg_nag = train_minibatch_nag(copy.deepcopy(netReg), dataInput_train, dataTarget_train, epochs, learning_rate_nag, batch_size, loss_derivative, grad_clip = grad_clip_nag)\n",
    "net_reg_adam = train_minibatch_adam(copy.deepcopy(netReg), dataInput_train, dataTarget_train, epochs, learning_rate_adam, batch_size, loss_derivative, grad_clip = grad_clip_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9280e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating error\n",
    "error_reg_sgd = MeanSquaredError(dataTarget_test,net_reg_sgd.predictRegression(dataInput_test))\n",
    "error_reg_momentum = MeanSquaredError(dataTarget_test,net_reg_sgd_momentum.predictRegression(dataInput_test))\n",
    "error_reg_rmsprop = MeanSquaredError(dataTarget_test,net_reg_rmsprop.predictRegression(dataInput_test))\n",
    "error_reg_nag = MeanSquaredError(dataTarget_test,net_reg_nag.predictRegression(dataInput_test))\n",
    "error_reg_adam = MeanSquaredError(dataTarget_test,net_reg_adam.predictRegression(dataInput_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d84ebb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error sgd: 9.910048655820084e+27\n",
      "Mean square error momentum: 1.637946516223739e+32\n",
      "Mean square error rmsprop: 1.4638229088300197e+37\n",
      "Mean square error nag: 9.876863598382898e+27\n",
      "Mean square error adam: 1.057742113488023e+46\n"
     ]
    }
   ],
   "source": [
    "#Printing errors\n",
    "print(f\"Mean square error sgd: {error_reg_sgd}\")\n",
    "print(f\"Mean square error momentum: {error_reg_momentum}\")\n",
    "print(f\"Mean square error rmsprop: {error_reg_rmsprop}\")\n",
    "print(f\"Mean square error nag: {error_reg_nag}\")\n",
    "print(f\"Mean square error adam: {error_reg_adam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4677899",
   "metadata": {},
   "source": [
    "Binary classification testing (on tabular data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a85992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting general network hyperparameters'\n",
    "epochs = 1000\n",
    "batch_size = 12\n",
    "loss_derivative = BinaryCrossEntropyDerivative\n",
    "size_test_set = 0.1\n",
    "#sgd specific\n",
    "learning_rate_sgd = 0.005\n",
    "grad_clip_sgd = 10\n",
    "#sgd_momentum specific\n",
    "learning_rate_sgd_momentum = 0.001\n",
    "grad_clip_sgd_momentum = 10\n",
    "momentum_sgd_momentum = 0.95\n",
    "#rmsprop specific\n",
    "learning_rate_rmsprop = 0.001\n",
    "grad_clip_rmsprop = 0\n",
    "#nag specific\n",
    "learning_rate_nag = 0.0005\n",
    "grad_clip_nag = 10\n",
    "momentum_nag = 0.6\n",
    "#adam specific\n",
    "learning_rate_adam = 0.005\n",
    "grad_clip_adam = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a3c6c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preparation for classification training\n",
    "dataClass = data_NoId\n",
    "dataInput= dataClass.iloc[:,1:].to_numpy()#all features without without diagn\n",
    "dataTarget_desc = dataClass.loc[:,\"Diagnosis\"].to_numpy()\n",
    "dataInput = dataInput.T\n",
    "dataTarget_desc = dataTarget_desc[np.newaxis,:]\n",
    "dataTarget_bin = np.zeros(dataTarget_desc.shape)\n",
    "dataTarget_bin[dataTarget_desc == \"M\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3daff5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting data split\n",
    "n_samples = dataTarget_bin.size\n",
    "indices = np.arange(0,n_samples)\n",
    "indices_test = np.random.permutation(round(n_samples*0.2))\n",
    "indices_train = list(set(indices) - set(indices_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb053492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting train set\n",
    "dataInput_train = dataInput[:,indices_train]\n",
    "dataTarget_train = dataTarget_bin[:,indices_train]\n",
    "#getting test set\n",
    "dataInput_test = dataInput[:,indices_test]\n",
    "dataTarget_test = dataTarget_bin[:,indices_test]\n",
    "#standarizing data\n",
    "meanDataInput_train = np.mean(dataInput_train, axis=1)\n",
    "meanDataInput_train = meanDataInput_train[:,np.newaxis]\n",
    "stdDataInput_train = np.std(dataInput_train, axis=1)\n",
    "stdDataInput_train = stdDataInput_train[:,np.newaxis]\n",
    "dataInput_train = (dataInput_train - meanDataInput_train) / stdDataInput_train\n",
    "dataInput_test =  (dataInput_test - meanDataInput_train) / stdDataInput_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b68ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring network\n",
    "netClassBin = FNN([30,64, 32, 16, 8, 4, 2, 1],\n",
    "          [relu,sigmoid],\n",
    "          method_ini=\"HeNor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce334eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models training (different optimizer)\n",
    "net_classBin_sgd = train_minibatch_sgd(copy.deepcopy(netClassBin), dataInput_train, dataTarget_train, epochs, learning_rate_sgd , batch_size, loss_derivative, grad_clip = grad_clip_sgd)\n",
    "net_classBin_sgd_momentum = train_minibatch_sgd_momentum(copy.deepcopy(netClassBin), dataInput_train, dataTarget_train, epochs, learning_rate_sgd_momentum, batch_size, loss_derivative, momentum = momentum_sgd_momentum, grad_clip = grad_clip_sgd_momentum)\n",
    "net_classBin_rmsprop = train_minibatch_rmsprop(copy.deepcopy(netClassBin), dataInput_train, dataTarget_train, epochs, learning_rate_rmsprop, batch_size, loss_derivative, grad_clip = grad_clip_rmsprop)\n",
    "net_classBin_nag = train_minibatch_nag(copy.deepcopy(netClassBin), dataInput_train, dataTarget_train, epochs, learning_rate_nag, batch_size, loss_derivative, grad_clip = grad_clip_nag)\n",
    "net_classBin_adam = train_minibatch_adam(copy.deepcopy(netClassBin), dataInput_train, dataTarget_train, epochs, learning_rate_adam, batch_size, loss_derivative, grad_clip = grad_clip_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de605f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy calculation\n",
    "confMatComp_classBin_sgd = getConfMatCompBin(dataTarget_test,net_classBin_sgd.predictClassBinary(dataInput_test))\n",
    "confMatComp_classBin_momentum = getConfMatCompBin(dataTarget_test,net_classBin_sgd_momentum.predictClassBinary(dataInput_test))\n",
    "confMatComp_classBin_rmsprop = getConfMatCompBin(dataTarget_test,net_classBin_rmsprop.predictClassBinary(dataInput_test))\n",
    "confMatComp_classBin_nag = getConfMatCompBin(dataTarget_test,net_classBin_nag.predictClassBinary(dataInput_test))\n",
    "confMatComp_classBin_adam = getConfMatCompBin(dataTarget_test,net_classBin_adam.predictClassBinary(dataInput_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dfeebc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sgd: 0.956140350877193\n",
      "Accuracy momentum: 0.956140350877193\n",
      "Accuracy rmsprop: 0.9649122807017544\n",
      "Accuracy nag: 0.956140350877193\n",
      "Accuracy adam: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "#getting accuracy\n",
    "accuracy_classBin_sgd = getAccuracyBin(confMatComp_classBin_sgd[0],confMatComp_classBin_sgd[1],confMatComp_classBin_sgd[2],confMatComp_classBin_sgd[3])\n",
    "accuracy_classBin_momentum = getAccuracyBin(confMatComp_classBin_momentum[0],confMatComp_classBin_momentum[1],confMatComp_classBin_momentum[2],confMatComp_classBin_momentum[3])\n",
    "accuracy_classBin_rmsprop = getAccuracyBin(confMatComp_classBin_rmsprop[0],confMatComp_classBin_rmsprop[1],confMatComp_classBin_rmsprop[2],confMatComp_classBin_rmsprop[3])\n",
    "accuracy_classBin_nag = getAccuracyBin(confMatComp_classBin_nag[0],confMatComp_classBin_nag[1],confMatComp_classBin_nag[2],confMatComp_classBin_nag[3])\n",
    "accuracy_classBin_adam = getAccuracyBin(confMatComp_classBin_adam[0],confMatComp_classBin_adam[1],confMatComp_classBin_adam[2],confMatComp_classBin_adam[3])\n",
    "#printing accuracy\n",
    "print(f\"Accuracy sgd: {accuracy_classBin_sgd}\")\n",
    "print(f\"Accuracy momentum: {accuracy_classBin_momentum}\")\n",
    "print(f\"Accuracy rmsprop: {accuracy_classBin_rmsprop}\")\n",
    "print(f\"Accuracy nag: {accuracy_classBin_nag}\")\n",
    "print(f\"Accuracy adam: {accuracy_classBin_adam}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e17bfb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision sgd: 0.9846153846153847\n",
      "Precision momentum: 0.9846153846153847\n",
      "Precision rmsprop: 0.9848484848484849\n",
      "Precision nag: 0.9846153846153847\n",
      "Precision adam: 0.9846153846153847\n"
     ]
    }
   ],
   "source": [
    "#getting Precision\n",
    "precision_classBin_sgd = getPrecisionBin(confMatComp_classBin_sgd[0],confMatComp_classBin_sgd[2])\n",
    "precision_classBin_momentum = getPrecisionBin(confMatComp_classBin_momentum[0],confMatComp_classBin_momentum[2])\n",
    "precision_classBin_rmsprop = getPrecisionBin(confMatComp_classBin_rmsprop[0],confMatComp_classBin_rmsprop[2])\n",
    "precision_classBin_nag = getPrecisionBin(confMatComp_classBin_nag[0],confMatComp_classBin_nag[2])\n",
    "precision_classBin_adam = getPrecisionBin(confMatComp_classBin_adam[0],confMatComp_classBin_adam[2])\n",
    "#printing Precision\n",
    "print(f\"Precision sgd: {precision_classBin_sgd}\")\n",
    "print(f\"Precision momentum: {precision_classBin_momentum}\")\n",
    "print(f\"Precision rmsprop: {precision_classBin_rmsprop}\")\n",
    "print(f\"Precision nag: {precision_classBin_nag}\")\n",
    "print(f\"Precision adam: {precision_classBin_adam}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6155dda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall sgd: 0.9846153846153847\n",
      "Recall momentum: 0.9846153846153847\n",
      "Recall rmsprop: 0.9848484848484849\n",
      "Recall nag: 0.9846153846153847\n",
      "Recall adam: 0.9846153846153847\n"
     ]
    }
   ],
   "source": [
    "#getting Recall\n",
    "recall_classBin_sgd = getRecallBin(confMatComp_classBin_sgd[0],confMatComp_classBin_sgd[3])\n",
    "recall_classBin_momentum = getRecallBin(confMatComp_classBin_momentum[0],confMatComp_classBin_momentum[3])\n",
    "recall_classBin_rmsprop = getRecallBin(confMatComp_classBin_rmsprop[0],confMatComp_classBin_rmsprop[3])\n",
    "recall_classBin_nag = getRecallBin(confMatComp_classBin_nag[0],confMatComp_classBin_nag[3])\n",
    "recall_classBin_adam = getRecallBin(confMatComp_classBin_adam[0],confMatComp_classBin_adam[3])\n",
    "#printing Recall\n",
    "print(f\"Recall sgd: {precision_classBin_sgd}\")\n",
    "print(f\"Recall momentum: {precision_classBin_momentum}\")\n",
    "print(f\"Recall rmsprop: {precision_classBin_rmsprop}\")\n",
    "print(f\"Recall nag: {precision_classBin_nag}\")\n",
    "print(f\"Recall adam: {precision_classBin_adam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e953c81d",
   "metadata": {},
   "source": [
    "Multi-class classification (on MNIST dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c50395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the data for multi class classification (no need to have data physically downloaded)\n",
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5514c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting general network hyperparameters'\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "loss_derivative = SoftmaxCrossEntropyDerivative\n",
    "size_test_set = 0.1\n",
    "#sgd specific\n",
    "learning_rate_sgd = 0.0001\n",
    "grad_clip_sgd = 10\n",
    "#sgd_momentum specific\n",
    "learning_rate_sgd_momentum = 0.0001\n",
    "grad_clip_sgd_momentum = 10\n",
    "momentum_sgd_momentum = 0.95\n",
    "#rmsprop specific\n",
    "learning_rate_rmsprop = 0.0001\n",
    "grad_clip_rmsprop = 0\n",
    "#nag specific\n",
    "learning_rate_nag = 0.0001\n",
    "grad_clip_nag = 10\n",
    "momentum_nag = 0.6\n",
    "#adam specific\n",
    "learning_rate_adam = 0.0001\n",
    "grad_clip_adam = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ffe8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing dataset\n",
    "dataInput = X.T\n",
    "dataTarget = y[np.newaxis,:]\n",
    "dataTarget_one_hot = one_hot_encode(dataTarget,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48264c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting data split\n",
    "n_samples = dataTarget.size\n",
    "indices = np.arange(0,n_samples)\n",
    "indices_test = np.random.permutation(round(n_samples*0.2))\n",
    "indices_train = list(set(indices) - set(indices_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87f88c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting train set\n",
    "dataInput_train = dataInput[:,indices_train]\n",
    "dataTarget_train = dataTarget_one_hot[:,indices_train]\n",
    "#getting test set\n",
    "dataInput_test = dataInput[:,indices_test]\n",
    "dataTarget_test = dataTarget_one_hot[:,indices_test]\n",
    "#normalization\n",
    "dataInput_train = dataInput_train/255.0\n",
    "dataInput_test =  dataInput_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d6cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring network\n",
    "netClassMulti = FNN([784,1024,512, 256, 128, 10],\n",
    "          [relu,softmax],\n",
    "          method_ini=\"HeNor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1d8200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models training (different optimizer)\n",
    "net_classMulti_sgd = train_minibatch_sgd(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_sgd , batch_size, loss_derivative, grad_clip = grad_clip_sgd)\n",
    "net_classMulti_sgd_momentum = train_minibatch_sgd_momentum(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_sgd_momentum, batch_size, loss_derivative, momentum = momentum_sgd_momentum, grad_clip = grad_clip_sgd_momentum)\n",
    "net_classMulti_rmsprop = train_minibatch_rmsprop(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_rmsprop, batch_size, loss_derivative, grad_clip = grad_clip_rmsprop)\n",
    "net_classMulti_nag = train_minibatch_nag(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_nag, batch_size, loss_derivative, grad_clip = grad_clip_nag)\n",
    "net_classMulti_adam = train_minibatch_adam(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_adam, batch_size, loss_derivative, grad_clip = grad_clip_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "847c9bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sgd: 0.9296428571428571\n",
      "Accuracy momentum: 0.9779285714285715\n",
      "Accuracy rmsprop: 0.9805\n",
      "Accuracy nag: 0.9712142857142857\n",
      "Accuracy adam: 0.9821428571428571\n"
     ]
    }
   ],
   "source": [
    "#decoding test set\n",
    "dataTarget_test_decode = one_hot_decode(dataTarget_test)\n",
    "#accuracy calculation\n",
    "accuracy_classMulti_sgd = getAccuracy(dataTarget_test_decode,net_classMulti_sgd.predictClassMulti(dataInput_test))\n",
    "accuracy_classMulti_momentum = getAccuracy(dataTarget_test_decode,net_classMulti_sgd_momentum.predictClassMulti(dataInput_test))\n",
    "accuracy_classMulti_rmsprop = getAccuracy(dataTarget_test_decode,net_classMulti_rmsprop.predictClassMulti(dataInput_test))\n",
    "accuracy_classMulti_nag = getAccuracy(dataTarget_test_decode,net_classMulti_nag.predictClassMulti(dataInput_test))\n",
    "accuracy_classMulti_adam = getAccuracy(dataTarget_test_decode,net_classMulti_adam.predictClassMulti(dataInput_test))\n",
    "#printing accuracy\n",
    "print(f\"Accuracy sgd: {accuracy_classMulti_sgd}\")\n",
    "print(f\"Accuracy momentum: {accuracy_classMulti_momentum}\")\n",
    "print(f\"Accuracy rmsprop: {accuracy_classMulti_rmsprop}\")\n",
    "print(f\"Accuracy nag: {accuracy_classMulti_nag}\")\n",
    "print(f\"Accuracy adam: {accuracy_classMulti_adam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4473b25",
   "metadata": {},
   "source": [
    "Multi-class classification (on CIFAR-10 dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c17a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting CIFAR-10 dataset (no need to have data physically downloaded)\n",
    "import keras\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e8349fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting general network hyperparameters'\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "loss_derivative = SoftmaxCrossEntropyDerivative\n",
    "size_test_set = 0.1\n",
    "#sgd specific\n",
    "learning_rate_sgd = 0.0001\n",
    "grad_clip_sgd = 10\n",
    "#sgd_momentum specific\n",
    "learning_rate_sgd_momentum = 0.0001\n",
    "grad_clip_sgd_momentum = 10\n",
    "momentum_sgd_momentum = 0.95\n",
    "#rmsprop specific\n",
    "learning_rate_rmsprop = 0.0001\n",
    "grad_clip_rmsprop = 0\n",
    "#nag specific\n",
    "learning_rate_nag = 0.0001\n",
    "grad_clip_nag = 10\n",
    "momentum_nag = 0.6\n",
    "#adam specific\n",
    "learning_rate_adam = 0.0001\n",
    "grad_clip_adam = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cbd9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing dataset for training and testing\n",
    "x_train_flattened = x_train.reshape(50000,-1)\n",
    "x_test_flattened = x_test.reshape(10000,-1)\n",
    "y_train_flattened = y_train.reshape(-1)\n",
    "y_test_flattened = y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f24fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one_hot_encoding targets(y)\n",
    "dataTarget_train = one_hot_encode(y_train_flattened.T,10)\n",
    "dataTarget_test = one_hot_encode(y_test_flattened.T,10)\n",
    "#normalization(plus transpose to allign dataset to network architecture)\n",
    "dataInput_train = (x_train_flattened.T/255.0)\n",
    "dataInput_test =  (x_test_flattened.T/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ad376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring network\n",
    "netClassMulti = FNN([3072,1024,512, 256, 128, 10],\n",
    "          [relu,softmax],\n",
    "          method_ini=\"HeNor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06f790cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models training (different optimizer)\n",
    "net_classMulti_sgd = train_minibatch_sgd(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_sgd , batch_size, loss_derivative, grad_clip = grad_clip_sgd)\n",
    "net_classMulti_sgd_momentum = train_minibatch_sgd_momentum(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_sgd_momentum, batch_size, loss_derivative, momentum = momentum_sgd_momentum, grad_clip = grad_clip_sgd_momentum)\n",
    "net_classMulti_rmsprop = train_minibatch_rmsprop(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_rmsprop, batch_size, loss_derivative, grad_clip = grad_clip_rmsprop)\n",
    "net_classMulti_nag = train_minibatch_nag(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_nag, batch_size, loss_derivative, grad_clip = grad_clip_nag)\n",
    "net_classMulti_adam = train_minibatch_adam(copy.deepcopy(netClassMulti), dataInput_train, dataTarget_train, epochs, learning_rate_adam, batch_size, loss_derivative, grad_clip = grad_clip_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afbbc352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy sgd: 0.4136\n",
      "Accuracy momentum: 0.5082\n",
      "Accuracy rmsprop: 0.5344\n",
      "Accuracy nag: 0.4959\n",
      "Accuracy adam: 0.5344\n"
     ]
    }
   ],
   "source": [
    "#decoding test set\n",
    "dataTarget_test_decode = one_hot_decode(dataTarget_test)\n",
    "#accuracy calculation\n",
    "accuracy_classMulti_sgd = getAccuracy(dataTarget_test_decode,net_classMulti_sgd.predictClassMulti(dataInput_test))\n",
    "accuracy_classMulti_momentum = getAccuracy(dataTarget_test_decode,net_classMulti_sgd_momentum.predictClassMulti(dataInput_test))\n",
    "accuracy_classMulti_rmsprop = getAccuracy(dataTarget_test_decode,net_classMulti_rmsprop.predictClassMulti(dataInput_test))\n",
    "accuracy_classMulti_nag = getAccuracy(dataTarget_test_decode,net_classMulti_nag.predictClassMulti(dataInput_test))\n",
    "accuracy_classMulti_adam = getAccuracy(dataTarget_test_decode,net_classMulti_adam.predictClassMulti(dataInput_test))\n",
    "#printing accuracy\n",
    "print(f\"Accuracy sgd: {accuracy_classMulti_sgd}\")\n",
    "print(f\"Accuracy momentum: {accuracy_classMulti_momentum}\")\n",
    "print(f\"Accuracy rmsprop: {accuracy_classMulti_rmsprop}\")\n",
    "print(f\"Accuracy nag: {accuracy_classMulti_nag}\")\n",
    "print(f\"Accuracy adam: {accuracy_classMulti_adam}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trying",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
