{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c419d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FNN import FNN\n",
    "from Layer import Layer\n",
    "from Neuron import Neuron\n",
    "import numpy as np\n",
    "from ActivFunctions import  *\n",
    "from InitFunctions import  *\n",
    "from SuppFunctions import  *\n",
    "from ErrorClasses import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ea47f5",
   "metadata": {},
   "source": [
    "Neuron Class functionality testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb8c9de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zero initialization\n",
    "neuron = Neuron(2,identity)\n",
    "#forward pass test\n",
    "testInputFormat([1.0,1.0],neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ef7148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random initialization\n",
    "neuron = Neuron(2,identity,method_ini=\"Random\")\n",
    "#forward pass test\n",
    "testInputFormat([1.0,1.0],neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbe12c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization from list\n",
    "vector = [1.0,2.0,3.5]\n",
    "neuron = Neuron(vector,identity)\n",
    "#forward pass test\n",
    "testInputFormat([1.0,1.0],neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9f0a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization from vector\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "neuron = Neuron(vector,identity)\n",
    "#forward pass test\n",
    "testInputFormat([1.0,1.0],neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7a43849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization from row vector(2D array)\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "vector_row = vector[np.newaxis,:]\n",
    "neuron = Neuron(vector_row,identity)\n",
    "#forward pass test\n",
    "testInputFormat([1.0,1.0],neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6193892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization from column vector(2D array)\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "vector_column = vector[:,np.newaxis]\n",
    "neuron = Neuron(vector_column,identity)\n",
    "#forward pass test\n",
    "testInputFormat([1.0,1.0],neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b62878a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for: no function given as activation function\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for activation function initialization. Given variable is not a function and thus can not be used as activation function.\n",
      "Test for: not vector given for weights initialization (2 dim)\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given variable is not an vector (not column or row vector in 2 dim), so it is unsuitable for neuron weight initialization.\n",
      "Test for: not vector given for weights initialization (higher than 2 dim)\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given variable is not an vector (due to more than 2 dim), so it is unsuitable for neuron weight initialization.\n",
      "Test for: wrong weights given for initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given values are not a rational numbers and thus can not be used as weight values.\n",
      "Test for: wrong var type given in list for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Values given in list are not  numbers and thus can not be used as weight values.\n",
      "Test for: input propagation (forward pass) - inproper dimension of input\n",
      "Correct errors was caught. Error: Given array is of size not supported by implementation. Supported dimensions: 1,2.\n",
      "Test for: input propagation (forward pass) - wrong value types in input: they are not rational numbers\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Given values are not a rational numbers and thus can not be used to get output from neuron.\n",
      "Test for: input propagation (forward pass) - given variable is of not supported type for list\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Values given in list are not numbers and thus can not be used as input to neuron.\n",
      "Test for: input propagation (forward pass) - given variable is of not supported type\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Not supported data type given.\n",
      "Test for: input propagation (forward pass) - given input is too small to match neuron dimensions\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Input does not match network, i.e. matrix multiplication cannot be done due to mismatch of dimensions.\n",
      "Test for: input propagation (forward pass) - given input is too small to match neuron dimensions\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Input does not match network, i.e. matrix multiplication cannot be done due to mismatch of dimensions.\n"
     ]
    }
   ],
   "source": [
    "#error messages testing\n",
    "print(\"Test for: no function given as activation function\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    errorNeuron = Neuron(vector,1)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not vector given for weights initialization (2 dim)\")\n",
    "try:\n",
    "    vector = np.array([[1.0,2.0,3.5],[1.0,2.0,3.5]])\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not vector given for weights initialization (higher than 2 dim)\")\n",
    "try:\n",
    "    vector = np.array([[[1.0,2.0,3.5],[1.0,2.0,3.5]],[[1.0,2.0,3.5],[1.0,2.0,3.5]]])\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong weights given for initialization\")\n",
    "try:\n",
    "    vector = np.array([\"1.0\",\"2.0\",\"3.5\"])\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong var type given in list for weight initialization\")\n",
    "try:\n",
    "    vector = [\"as\",\"2.0\",\"3.5\"]\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - inproper dimension of input\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = np.array([[[1.0,1.0],[1.0,1.0]],[[1.0,1.0],[1.0,1.0]]]) \n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedArrayDimGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - wrong value types in input: they are not rational numbers\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = np.array([1.0 + 3j,1.0]) \n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given variable is of not supported type for list\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = [\"a\",\"1.0\"]\n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given variable is of not supported type\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = \"a\"\n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given input is too small to match neuron dimensions\")\n",
    "try:\n",
    "    #wrong input (too small)\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    neuronTest = Neuron(vector,identity)\n",
    "    inputTestErrorSmall = np.array([1.0])\n",
    "    neuronTest.forward(inputTestErrorSmall)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given input is too small to match neuron dimensions\")\n",
    "try:\n",
    "    #wrong input (too big)\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    neuronTest = Neuron(vector,identity)\n",
    "    inputTestErrorBig = np.array([[1.0],[1.0],[1.0],[1.0]])\n",
    "    neuronTest.forward(inputTestErrorBig)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68632b0b",
   "metadata": {},
   "source": [
    "Layer class implementation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61504054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization by number of dim in vector\n",
    "dim_layer = np.array([4,5])\n",
    "testLayer = Layer(dim_layer,identity,method_ini=\"Random\")\n",
    "#testing forward pass\n",
    "testInputFormat([1.0,5.4,-1.0,21.0,-1.0],testLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "637ade70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization by number of dim in list\n",
    "dim_layer = [4,5]\n",
    "testLayer = Layer(dim_layer,identity,method_ini=\"Random\")\n",
    "#testing forward pass\n",
    "testInputFormat([1.0,5.4,-1.0,21.0,-1.0],testLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "281ae9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization by giving weight array\n",
    "weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "testLayer = Layer(weights,identity,method_ini=\"Random\")\n",
    "#testing forward pass\n",
    "testInputFormat([1.0,5.4,-1.0,21.0,-1.0],testLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7632900b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization by giving weight array and function (single) from list\n",
    "weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "testLayer = Layer(weights,[identity],method_ini=\"Random\")\n",
    "#testing forward pass\n",
    "testInputFormat([1.0,5.4,-1.0,21.0,-1.0],testLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c55d285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization by giving weight array and identity function (mutliple same) from list\n",
    "weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "activation_functions = [identity,identity,identity]\n",
    "testLayer = Layer(weights,activation_functions,method_ini=\"Random\")\n",
    "#testing forward pass\n",
    "testInputFormat([1.0,5.4,-1.0,21.0,-1.0],testLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5c528d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization by giving weight array and identity function (mutliple different) from list\n",
    "weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "activation_functions = [sigmoid,relu,leaky_relu]\n",
    "testLayer = Layer(weights,activation_functions)\n",
    "#testing forward pass\n",
    "testInputFormat([1.0,5.4,-1.0,21.0,-1.0],testLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "140d6345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for: wrong var type (not number) given in list for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given values are not integers and thus can not represent of layer weights matrix.\n",
      "Test for: wrong var type given (number, but no int) in list for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given values are not integers and thus can not represent of layer weights matrix.\n",
      "Test for: wrong var type (not number) given in 1D array for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given values are not integers and thus can not represent of layer weights matrix.\n",
      "Test for: wrong var type given (number, but no int) in 1D array for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given values are not integers and thus can not represent of layer weights matrix.\n",
      "Test for: wrong dimensions of given 1D array for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. In this implementation initialization by vector (1 dim) is only supported for dimensions to initialize. As there are only 2 dimensions to initialize layer any other are unsuitable and raise error due to ambiguity\n",
      "Test for: not rational numbers given in 2D array for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given values are not a rational numbers and thus can not be used as weight values.\n",
      "Test for: not enough information given in 2D array for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given array have insuffiecient information to represent weights of layer.\n",
      "Test for: bigger than 2D was given for array for weight initialization\n",
      "Correct errors was caught. Error: Given array is of size not supported by implementation. Supported dimensions: 1,2.\n",
      "Test for: not supported data type given for array for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Not supported data type given.\n",
      "Test for: not supported data type given for array for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Not supported data type given.\n",
      "Test for: not compatible amount of activation functions given to the amount of neurons for activation function initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for activation functions initialization. Given activation functions number does not match number of neurons in layer\n",
      "Test for: not activation function given (inside list) for activation function initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for activation functions initialization. Given variable is not function\n",
      "Test for: not activation function given (standalone) for activation function initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for activation functions initialization. Not supported data type given.\n",
      "Test for: input propagation, too much dimensions in input\n",
      "Correct errors was caught. Error: Given array is of size not supported by implementation. Supported dimensions: 1,2.\n",
      "Test for: input propagation, complex input\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Given values are not a rational numbers and thus can not be used to get output from  layer neurons.\n",
      "Test for: input propagation, wrong data type of input\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Not supported data type given.\n",
      "Test for: input propagation, wrong data type of input in list\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Values given in list are not numbers and thus can not be used as input to neuron.\n",
      "Test for: input propagation, input does not match layer neurons\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Input does not match network, i.e. matrix multiplication cannot be done due to mismatch of dimensions.\n"
     ]
    }
   ],
   "source": [
    "#error messages testing\n",
    "print(\"Test for: wrong var type (not number) given in list for weight initialization\")\n",
    "try:\n",
    "    vector = [\"as\",\"2.0\"]\n",
    "    testLayer = Layer(vector,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong var type given (number, but no int) in list for weight initialization\")\n",
    "try:\n",
    "    vector = [1,2.3]\n",
    "    testLayer = Layer(vector,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong var type (not number) given in 1D array for weight initialization\")\n",
    "try:\n",
    "    vector = np.array([\"as\",\"2.0\"])\n",
    "    testLayer = Layer(vector,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong var type given (number, but no int) in 1D array for weight initialization\")\n",
    "try:\n",
    "    vector = np.array([1,2.3])\n",
    "    testLayer = Layer(vector,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong dimensions of given 1D array for weight initialization\")\n",
    "try:\n",
    "    vector = np.array([1,2,1,1,2])\n",
    "    testLayer = Layer(vector,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not rational numbers given in 2D array for weight initialization\")\n",
    "try:\n",
    "    weights = np.array([[1.0 + 4j,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    testLayer = Layer(weights,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not enough information given in 2D array for weight initialization\")\n",
    "try:\n",
    "    weights = np.array([[]])\n",
    "    testLayer = Layer(weights,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: bigger than 2D was given for array for weight initialization\")\n",
    "try:\n",
    "    weights = np.array([[[2]]])\n",
    "    testLayer = Layer(weights,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedArrayDimGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not supported data type given for array for weight initialization\")\n",
    "try:\n",
    "    weights = \"hehe\"\n",
    "    testLayer = Layer(weights,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not supported data type given for array for weight initialization\")\n",
    "try:\n",
    "    weights = \"hehe\"\n",
    "    testLayer = Layer(weights,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not compatible amount of activation functions given to the amount of neurons for activation function initialization\")\n",
    "try:\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = [sigmoid,relu,leaky_relu,leaky_relu]\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not activation function given (inside list) for activation function initialization\")\n",
    "try:\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = [sigmoid,1,leaky_relu]\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not activation function given (standalone) for activation function initialization\")\n",
    "try:\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = 1\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation, too much dimensions in input\")\n",
    "try:\n",
    "    #Input data for input propagation (forward pass)\n",
    "    inputTestArray = np.array([[[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]],[[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]]])\n",
    "    #model ini\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = [sigmoid,sigmoid,leaky_relu]\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "    #forward pass test\n",
    "    testLayer.forward(inputTestArray)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedArrayDimGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation, complex input\")\n",
    "try:\n",
    "    #Input data for input propagation (forward pass)\n",
    "    inputTestVect = np.array([[1.0 + 3j],[1.0],[1.0],[1.0],[1.0]])\n",
    "    #model ini\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = [sigmoid,sigmoid,leaky_relu]\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "    #forward pass test\n",
    "    testLayer.forward(inputTestVect)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation, wrong data type of input\")\n",
    "try:\n",
    "    #Input data for input propagation (forward pass)\n",
    "    inputTestVect = \"sda\"\n",
    "    #model ini\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = [sigmoid,sigmoid,leaky_relu]\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "    #forward pass test\n",
    "    testLayer.forward(inputTestVect)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation, wrong data type of input in list\")\n",
    "try:\n",
    "    #Input data for input propagation (forward pass)\n",
    "    inputTestList =[\"a\",1.0,1.0,1.0,1.0]\n",
    "    inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "    #model ini\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = [sigmoid,sigmoid,leaky_relu]\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "    #forward pass test\n",
    "    testLayer.forward(inputTestList)\n",
    "    testLayer.forward(inputTestArray)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation, input does not match layer neurons\")\n",
    "try:\n",
    "    #Input data for input propagation (forward pass)\n",
    "    inputTestList = [1.0,1.0,1.0,1.0,1.0,1.0,1.0]\n",
    "    #model ini\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = [sigmoid,sigmoid,leaky_relu]\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "    #forward pass test\n",
    "    testLayer.forward(inputTestList)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0fad2d",
   "metadata": {},
   "source": [
    "FNN class implementation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "000a08cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.87449207 -0.16219061  0.89940144  0.77916095 -0.51660618 -0.49174924]\n",
      " [-0.67231437 -0.65074313 -0.46556027  0.83024198  0.76768169  0.19779758]\n",
      " [ 0.42424695  0.47136574 -0.91143031 -0.48896673 -0.6881352   0.22307742]\n",
      " [ 0.54568151  0.59454147  0.232539   -0.10939699 -0.49267358  0.20084447]\n",
      " [ 0.47273877  0.38738327 -0.96839182 -0.20977211 -0.60113074  0.97767681]]\n",
      "[[-0.51693962 -0.74753785  0.92474308  0.73924681  0.45351044  0.95900778]\n",
      " [ 0.87115088  0.87843055 -0.49070894 -0.69936913 -0.14357601  0.05521966]\n",
      " [-0.47505606 -0.96726524  0.74876198  0.9686345  -0.35667892  0.47835948]]\n",
      "[[ 0.25974547  0.66241534  0.05111208  0.42591857]\n",
      " [ 0.36781611  0.96519251  0.7577625  -0.98316103]]\n",
      "[[ 0.16138837 -0.75394675 -0.43895195]]\n",
      "[<function relu at 0x000001197FD4EB60>, <function relu at 0x000001197FD4EB60>, <function relu at 0x000001197FD4EB60>, <function relu at 0x000001197FD4EB60>, <function relu at 0x000001197FD4EB60>]\n",
      "[<function relu at 0x000001197FD4EB60>, <function relu at 0x000001197FD4EB60>, <function relu at 0x000001197FD4EB60>]\n",
      "[<function relu at 0x000001197FD4EB60>, <function relu at 0x000001197FD4EB60>]\n",
      "[<function identity at 0x000001197FD4E7A0>, <function identity at 0x000001197FD4E7A0>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization by number of dim in vector(list)\n",
    "dim_layer = [5,5,3,2,1]\n",
    "activ_func = [relu,identity]\n",
    "testNet = FNN(dim_layer,activ_func,method_ini=\"Random\")\n",
    "print(testNet.weights_list[0])\n",
    "print(testNet.weights_list[1])\n",
    "print(testNet.weights_list[2])\n",
    "print(testNet.weights_list[3])\n",
    "print(testNet.activ_functions_list_list[0])\n",
    "print(testNet.activ_functions_list_list[1])\n",
    "print(testNet.activ_functions_list_list[2])\n",
    "print(testNet.activ_functions_list_list[3])\n",
    "#testing forward pass\n",
    "testInputFormat([1.0,5.4,-1.0,21.0,-1.0],testNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8e1080e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization by number of dim in vector(1D array)\n",
    "dim_layer = np.array([5,5,3,2,1])\n",
    "activ_func = [relu,identity]\n",
    "testNet = FNN(dim_layer,activ_func,method_ini=\"Random\")\n",
    "#testing forward pass\n",
    "testInputFormat([1.0,5.4,-1.0,21.0,-1.0],testNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23d50129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.78746707, -0.39237576, -0.22218988,  0.0936168 , -0.3150142 ,\n",
      "         0.13413056],\n",
      "       [ 0.46518861, -0.23485562, -0.22459408, -0.21471567, -0.45118645,\n",
      "        -0.57193726],\n",
      "       [ 0.20265577, -0.03697937, -0.21791404, -0.55938501, -0.88923363,\n",
      "         0.83022662],\n",
      "       [ 0.80823816,  0.0440015 ,  0.35483957,  0.71342487,  0.20052473,\n",
      "         0.24732078],\n",
      "       [ 0.51664564,  0.58987538, -0.19738159, -0.44564232, -0.51216121,\n",
      "        -0.79156026]]), array([[-0.43931679,  0.7107981 ,  0.74015742,  0.27445154, -0.43016016,\n",
      "        -0.94292236],\n",
      "       [ 0.36492828,  0.91575449, -0.62162415,  0.66854204, -0.70900311,\n",
      "         0.98418117],\n",
      "       [ 0.21817373,  0.45097709, -0.49348632, -0.70773152, -0.58188654,\n",
      "         0.49866456]]), array([[-0.20232018, -0.56528111,  0.078821  ,  0.20949376],\n",
      "       [-0.50311424, -0.29342896, -0.57599385, -0.19337351]]), array([[-0.57261397, -0.99499021, -0.79906871]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dummy network ini\n",
    "dim_layer = np.array([5,5,3,2,1])\n",
    "activ_func = [relu,identity]\n",
    "testNet = FNN(dim_layer,activ_func,method_ini=\"Random\")\n",
    "#initialization by ready weight array\n",
    "dim_layer = testNet.weights_list\n",
    "print(dim_layer)\n",
    "activ_func = [relu,identity]\n",
    "testNet = FNN(dim_layer,activ_func,method_ini=\"Random\")\n",
    "#testing forward pass\n",
    "testInputFormat([1.0,5.4,-1.0,21.0,-1.0],testNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e89efa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization by number of dim in vector(1D array) and 1 activation function(as value)\n",
    "dim_layer = np.array([5,5,3,2,1])\n",
    "activ_func = identity\n",
    "testNet = FNN(dim_layer,activ_func,method_ini=\"Random\")\n",
    "#testing forward pass\n",
    "testInputFormat([1.0,5.4,-1.0,21.0,-1.0],testNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64719f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization by number of dim in vector(1D array) and 1 activation function(as list)\n",
    "dim_layer = np.array([5,5,3,2,1])\n",
    "activ_func = [identity]\n",
    "testNet = FNN(dim_layer,activ_func,method_ini=\"Random\")\n",
    "#testing forward pass\n",
    "testInputFormat([1.0,5.4,-1.0,21.0,-1.0],testNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60a23648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization by number of dim in vector(1D array) and 2 activation functions\n",
    "dim_layer = np.array([5,5,3,2,1])\n",
    "activ_func =  [relu,identity]\n",
    "testNet = FNN(dim_layer,activ_func,method_ini=\"Random\")\n",
    "#testing forward pass\n",
    "testInputFormat([1.0,5.4,-1.0,21.0,-1.0],testNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dbbab04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization by number of dim in vector(1D array) and activation function for each layer\n",
    "dim_layer = np.array([5,5,3,2,1])\n",
    "activ_func =  [relu,sigmoid,leaky_relu,identity]\n",
    "testNet = FNN(dim_layer,activ_func,method_ini=\"Random\")\n",
    "#testing forward pass\n",
    "testInputFormat([1.0,5.4,-1.0,21.0,-1.0],testNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c07485d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization by number of dim in vector(1D array) and activation function for each neuron\n",
    "dim_layer = np.array([5,5,3,2,1])\n",
    "l1 = [relu,sigmoid,sigmoid,leaky_relu,identity]\n",
    "l2 = [relu,sigmoid,sigmoid]\n",
    "l3 = [relu,sigmoid]\n",
    "l4 = [identity]\n",
    "activ_func =  [l1,l2,l3,l4]\n",
    "testNet = FNN(dim_layer,activ_func,method_ini=\"Random\")\n",
    "#testing forward pass\n",
    "testInputFormat([1.0,5.4,-1.0,21.0,-1.0],testNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#error messages testing\n",
    "print(\"Test for: not supported input for weights\")\n",
    "try:\n",
    "    dim_layer = \"[5,5,3,2,1]\"\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: array of not supported dimension\")\n",
    "try:\n",
    "    dim_layer = np.array([[5,5,3,2,1],[5,5,3,2,1]])\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedArrayDimGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: given numbers are not integers\")\n",
    "try:\n",
    "    dim_layer = np.array([5,5,3.1,2,1])\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not enough numbers given. Minimally required input and output layers cannot be created\")\n",
    "try:\n",
    "    dim_layer = np.array([5])\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6380a84d",
   "metadata": {},
   "source": [
    "Reload Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd529b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Reload order:\n",
    "modules_in_order = [\n",
    "    \"ActivFunctions\",\n",
    "    \"SuppFunctions\",\n",
    "    \"InitFunctions\",\n",
    "    \"Layer\",\n",
    "    \"FNN\",\n",
    "    \"TrainingFunctions\"\n",
    "]\n",
    "\n",
    "for m in modules_in_order:\n",
    "    if m in sys.modules:\n",
    "        importlib.reload(sys.modules[m])\n",
    "    else:\n",
    "        globals()[m] = importlib.import_module(m)\n",
    "\n",
    "print(\"All modules reloaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7120a838",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c07c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FNN import FNN\n",
    "from TrainingFunctions import backwards\n",
    "from LossFunctions import MeanSquaredErrorDerivative\n",
    "\n",
    "# Activations\n",
    "from ActivFunctions import identity, sigmoid, tanh, relu, leaky_relu\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d9cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Test 1: Single-Layer Network Gradient ===\")\n",
    "\n",
    "dim_layer = np.array([4, 5])   # 4 inputs -> 5 outputs\n",
    "testNet = FNN(dim_layer, identity, method_ini=\"Random\")\n",
    "\n",
    "inputTestVect = np.ones((4, 1))\n",
    "targetVect = 0.5 * np.ones((5, 1))\n",
    "\n",
    "grads = backwards(testNet, inputTestVect, targetVect, MeanSquaredErrorDerivative)\n",
    "\n",
    "print(\"\\nGradient matrix for single layer:\")\n",
    "print(grads[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13580c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Test 2: Deep 10-Layer Network ===\")\n",
    "\n",
    "dim_layer = np.array([\n",
    "    5, 8, 6, 7, 5, 9, 4, 3, 2, 4, 1\n",
    "])\n",
    "\n",
    "deepNet = FNN(dim_layer, identity, method_ini=\"Random\")\n",
    "\n",
    "inputVect = np.ones((5, 1))\n",
    "targetVect = np.array([[0.7]])\n",
    "\n",
    "grads = backwards(deepNet, inputVect, targetVect, MeanSquaredErrorDerivative)\n",
    "\n",
    "for i, g in enumerate(grads):\n",
    "    print(f\"\\nGradient matrix for layer {i}:\")\n",
    "    print(g)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02452",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
