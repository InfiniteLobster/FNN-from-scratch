{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c419d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from FNN import FNN\n",
    "from Layer import Layer\n",
    "from Neuron import Neuron\n",
    "\n",
    "from ActivFunctions import *\n",
    "from InitFunctions import *\n",
    "from SuppFunctions import *\n",
    "\n",
    "from LossFunctions import MeanSquaredError, MeanSquaredErrorDerivative\n",
    "from TrainingFunctions import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ea47f5",
   "metadata": {},
   "source": [
    "Neuron Class functionality testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f675aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTest = np.array([1.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb8c9de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.]]), array([[0.]])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zero initialization\n",
    "t0NeuronZero = Neuron(2,identity)\n",
    "print(t0NeuronZero.weight_vector.shape)\n",
    "t0NeuronZero.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ef7148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.70627357]]), array([[0.70627357]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random initialization\n",
    "t0NeuronRandom = Neuron(2,identity,method_ini=\"Random\")\n",
    "print(t0NeuronRandom.weight_vector.shape)\n",
    "t0NeuronRandom.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9f0a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  2.  3.5]\n",
      "(3,)\n",
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[6.5]]), array([[6.5]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization from vector\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "print(vector)\n",
    "print(vector.shape)\n",
    "t1Neuron = Neuron(vector,identity)\n",
    "print(t1Neuron.weight_vector.shape)\n",
    "t1Neuron.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7a43849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  2.  3.5]]\n",
      "(1, 3)\n",
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[6.5]]), array([[6.5]])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization from row vector(2D array)\n",
    "vector_row = vector[np.newaxis,:]\n",
    "print(vector_row)\n",
    "print(vector_row.shape)\n",
    "t2Neuron = Neuron(vector_row,identity)\n",
    "print(t2Neuron.weight_vector.shape)\n",
    "t2Neuron.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6193892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. ]\n",
      " [2. ]\n",
      " [3.5]]\n",
      "(3, 1)\n",
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[6.5]]), array([[6.5]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization from column vector(2D array)\n",
    "vector_column = vector[:,np.newaxis]\n",
    "print(vector_column)\n",
    "print(vector_column.shape)\n",
    "t3Neuron = Neuron(vector_column,identity)\n",
    "print(t3Neuron.weight_vector.shape)\n",
    "t3Neuron.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88aceccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.62823325, 0.62823325]]), array([[0.62823325, 0.62823325]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#array input\n",
    "t0NeuronRandom = Neuron(2,identity,method_ini=\"Random\")\n",
    "inputTest = np.array([[1.0,1.0],[1.0,1.0]])\n",
    "print(inputTest.shape)\n",
    "print(inputTest)\n",
    "print(t0NeuronRandom.weight_vector.shape)\n",
    "t0NeuronRandom.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62878a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#wrong activ function\u001b[39;00m\n\u001b[32m      2\u001b[39m vector = np.array([\u001b[32m1.0\u001b[39m,\u001b[32m2.0\u001b[39m,\u001b[32m3.5\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m errorNeuron = \u001b[43mNeuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Normal\\Documents\\DTU\\Deep learning\\Project\\code\\FNN-from-scratch\\Neuron.py:16\u001b[39m, in \u001b[36mNeuron.__init__\u001b[39m\u001b[34m(self, weights, activ_function, method_ini, datatype_weights, random_lower_bound, random_upper_bound)\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mself\u001b[39m.activ_function = activ_function\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\u001b[38;5;66;03m#if given variable is not an activation function, then class object can not be initialized due to lack (no activ function) or too much (e.g. vector of activ functions) of information. TO DO: implementing proper error\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m#based on the input (weights) the weight vector of the object would be assigned (or created, initialized). The choice of method is based on the data type of input\u001b[39;00m\n\u001b[32m     18\u001b[39m type_weights = \u001b[38;5;28mtype\u001b[39m(weights)\n",
      "\u001b[31mNotImplementedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#wrong activ function\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "errorNeuron = Neuron(vector,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ac2513",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#wrong input function\u001b[39;00m\n\u001b[32m      2\u001b[39m vector = np.array([\u001b[33m\"\u001b[39m\u001b[33m1.0\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m2.0\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m3.5\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m errorNeuron = \u001b[43mNeuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\u001b[43midentity\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Normal\\Documents\\DTU\\Deep learning\\Project\\code\\FNN-from-scratch\\Neuron.py:52\u001b[39m, in \u001b[36mNeuron.__init__\u001b[39m\u001b[34m(self, weights, activ_function, method_ini, datatype_weights, random_lower_bound, random_upper_bound)\u001b[39m\n\u001b[32m     50\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\u001b[38;5;66;03m#given variable is of unappropriate datatype. Error should be thrown. TO DO: error implementation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\u001b[38;5;66;03m#given variable is of type for which object initialization is not implemented. Appropriate error sould be passed. TO DO: implementing proper error\u001b[39;00m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[31mNotImplementedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#wrong input function\n",
    "vector = np.array([\"1.0\",\"2.0\",\"3.5\"])\n",
    "errorNeuron = Neuron(vector,identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af6baa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m neuronTest = Neuron(vector,identity)\n\u001b[32m      4\u001b[39m inputTestErrorSmall = np.array([\u001b[32m1.0\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mneuronTest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputTestErrorSmall\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Normal\\Documents\\DTU\\Deep learning\\Project\\code\\FNN-from-scratch\\Neuron.py:94\u001b[39m, in \u001b[36mNeuron.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     92\u001b[39m     output = [matrix_multi,activation_out]\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\u001b[38;5;66;03m#if inproper input was given and operation cannot proceed proper error should be raised. TO DO: implement proper error\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m#results are returned\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[31mNotImplementedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#wrong input (too small)\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "neuronTest = Neuron(vector,identity)\n",
    "inputTestErrorSmall = np.array([1.0])\n",
    "neuronTest.forward(inputTestErrorSmall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c63967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m inputTestErrorBig = np.array([[\u001b[32m1.0\u001b[39m],[\u001b[32m1.0\u001b[39m],[\u001b[32m1.0\u001b[39m],[\u001b[32m1.0\u001b[39m]])\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(inputTestErrorBig)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mneuronTest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputTestErrorBig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Normal\\Documents\\DTU\\Deep learning\\Project\\code\\FNN-from-scratch\\Neuron.py:94\u001b[39m, in \u001b[36mNeuron.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     92\u001b[39m     output = [matrix_multi,activation_out]\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\u001b[38;5;66;03m#if inproper input was given and operation cannot proceed proper error should be raised. TO DO: implement proper error\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m#results are returned\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[31mNotImplementedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#wrong input (too big)\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "neuronTest = Neuron(vector,identity)\n",
    "inputTestErrorBig = np.array([[1.0],[1.0],[1.0],[1.0]])\n",
    "print(inputTestErrorBig)\n",
    "neuronTest.forward(inputTestErrorBig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68632b0b",
   "metadata": {},
   "source": [
    "Layer class implementation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61504054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function ActivFunctions.identity(x)>,\n",
       " <function ActivFunctions.identity(x)>,\n",
       " <function ActivFunctions.identity(x)>,\n",
       " <function ActivFunctions.identity(x)>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization by number of dim in vector\n",
    "dim_layer = np.array([4,5])\n",
    "testLayer = Layer(dim_layer,identity,method_ini=\"Random\")\n",
    "testLayer.weights_array\n",
    "testLayer.activ_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637ade70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[2.93741261],\n",
      "       [3.16570166],\n",
      "       [4.12556719],\n",
      "       [3.06488001]]), array([[2.93741261],\n",
      "       [3.16570166],\n",
      "       [4.12556719],\n",
      "       [3.06488001]])]\n",
      "[array([[2.93741261, 4.92025167],\n",
      "       [3.16570166, 6.10149423],\n",
      "       [4.12556719, 7.70806968],\n",
      "       [3.06488001, 5.19384362]]), array([[2.93741261, 4.92025167],\n",
      "       [3.16570166, 6.10149423],\n",
      "       [4.12556719, 7.70806968],\n",
      "       [3.06488001, 5.19384362]])]\n"
     ]
    }
   ],
   "source": [
    "#forward test pass\n",
    "inputTestVect = np.array([[1.0],[1.0],[1.0],[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "\n",
    "print(testLayer.forward(inputTestVect))\n",
    "print(testLayer.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0fad2d",
   "metadata": {},
   "source": [
    "FNN class implementation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "000a08cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28156461 0.66980571 0.61900519 0.09558239 0.64158846 0.83980218]\n",
      " [0.67968198 0.37002793 0.91374895 0.57998655 0.41853405 0.85563371]\n",
      " [0.07669919 0.91433914 0.37862469 0.13313974 0.29647039 0.08852724]\n",
      " [0.95751846 0.68891225 0.68969802 0.88200442 0.59904858 0.15260945]\n",
      " [0.27435503 0.18519506 0.66283938 0.40497699 0.09623416 0.12438847]]\n",
      "[[0.68030577 0.49412327 0.96877788 0.96247331 0.6735594  0.11385461]\n",
      " [0.00288413 0.41420213 0.28138484 0.10421633 0.28902314 0.64024188]\n",
      " [0.00594837 0.69361562 0.81496139 0.91313827 0.5032143  0.55503246]]\n",
      "[[0.34204032 0.32508896 0.88554357 0.15301817]\n",
      " [0.29299083 0.54682188 0.0127216  0.27421699]]\n",
      "[[0.46546055 0.19271379 0.14741595]]\n",
      "[<function identity at 0x00000140650BA5C0>, <function identity at 0x00000140650BA5C0>, <function identity at 0x00000140650BA5C0>, <function identity at 0x00000140650BA5C0>, <function identity at 0x00000140650BA5C0>]\n",
      "[<function identity at 0x00000140650BA5C0>, <function identity at 0x00000140650BA5C0>, <function identity at 0x00000140650BA5C0>]\n",
      "[<function identity at 0x00000140650BA5C0>, <function identity at 0x00000140650BA5C0>]\n",
      "[<function identity at 0x00000140650BA5C0>]\n",
      "[[array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]]), array([[3.14734854],\n",
      "       [3.81761316],\n",
      "       [1.88780038],\n",
      "       [3.96979118],\n",
      "       [1.7479891 ]]), array([[10.62376736],\n",
      "       [ 4.84397803],\n",
      "       [ 9.99187494]]), array([[9.61420176],\n",
      "       [8.90386432]]), array([[3.63082139]])], [array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]]), array([[3.14734854],\n",
      "       [3.81761316],\n",
      "       [1.88780038],\n",
      "       [3.96979118],\n",
      "       [1.7479891 ]]), array([[10.62376736],\n",
      "       [ 4.84397803],\n",
      "       [ 9.99187494]]), array([[9.61420176],\n",
      "       [8.90386432]]), array([[3.63082139]])]]\n",
      "[[array([[1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.]]), array([[3.14734854, 6.01313248],\n",
      "       [3.81761316, 6.95554434],\n",
      "       [1.88780038, 3.69890157],\n",
      "       [3.96979118, 6.9820639 ],\n",
      "       [1.7479891 , 3.22162316]]), array([[10.62376736, 19.0196374 ],\n",
      "       [ 4.84397803,  8.91680319],\n",
      "       [ 9.99187494, 18.52443945]]), array([[ 9.61420176, 17.2559079 ],\n",
      "       [ 8.90386432, 15.8864968 ]]), array([[3.63082139, 6.13283491]])], [array([[1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.]]), array([[3.14734854, 6.01313248],\n",
      "       [3.81761316, 6.95554434],\n",
      "       [1.88780038, 3.69890157],\n",
      "       [3.96979118, 6.9820639 ],\n",
      "       [1.7479891 , 3.22162316]]), array([[10.62376736, 19.0196374 ],\n",
      "       [ 4.84397803,  8.91680319],\n",
      "       [ 9.99187494, 18.52443945]]), array([[ 9.61420176, 17.2559079 ],\n",
      "       [ 8.90386432, 15.8864968 ]]), array([[3.63082139, 6.13283491]])]]\n"
     ]
    }
   ],
   "source": [
    "#initialization by number of dim in vector\n",
    "dim_layer = np.array([5,5,3,2,1])\n",
    "testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "print(testNet.weights_list[0])\n",
    "print(testNet.weights_list[1])\n",
    "print(testNet.weights_list[2])\n",
    "print(testNet.weights_list[3])\n",
    "print(testNet.activ_functions_list[0])\n",
    "print(testNet.activ_functions_list[1])\n",
    "print(testNet.activ_functions_list[2])\n",
    "print(testNet.activ_functions_list[3])\n",
    "#forward test pass\n",
    "inputTestVect = np.array([[1.0],[1.0],[1.0],[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "\n",
    "print(testNet.forward(inputTestVect))\n",
    "print(testNet.forward(inputTestArray))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a311f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient matrix of the single layer:\n",
      "[[1.62298249 1.62298249 1.62298249 1.62298249 1.62298249]\n",
      " [2.10962022 2.10962022 2.10962022 2.10962022 2.10962022]\n",
      " [2.2202619  2.2202619  2.2202619  2.2202619  2.2202619 ]\n",
      " [1.55843506 1.55843506 1.55843506 1.55843506 1.55843506]\n",
      " [2.85182546 2.85182546 2.85182546 2.85182546 2.85182546]]\n"
     ]
    }
   ],
   "source": [
    "dim_layer = np.array([4, 5])\n",
    "testNet = FNN(dim_layer, identity, method_ini=\"Random\")\n",
    "\n",
    "inputTestVect = np.array([[1.0],\n",
    "                          [1.0],\n",
    "                          [1.0],\n",
    "                          [1.0]])\n",
    "\n",
    "targetVect = np.array([[0.5],\n",
    "                       [0.5],\n",
    "                       [0.5],\n",
    "                       [0.5],\n",
    "                       [0.5]])\n",
    "\n",
    "grads = backwards(testNet, inputTestVect, targetVect, MeanSquaredErrorDerivative)\n",
    "\n",
    "print(\"Gradient matrix of the single layer:\")\n",
    "print(grads[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679decc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Gradients for Deep 10-Layer Network ===\n",
      "\n",
      "Gradient matrix for layer 0:\n",
      "[[11431646.69137829 11431646.69137829 11431646.69137829 11431646.69137829\n",
      "  11431646.69137829 11431646.69137829]\n",
      " [12454478.05899259 12454478.05899259 12454478.05899259 12454478.05899259\n",
      "  12454478.05899259 12454478.05899259]\n",
      " [ 8278386.61528031  8278386.61528031  8278386.61528031  8278386.61528031\n",
      "   8278386.61528031  8278386.61528031]\n",
      " [11667852.28042965 11667852.28042965 11667852.28042965 11667852.28042965\n",
      "  11667852.28042965 11667852.28042965]\n",
      " [14451752.99181419 14451752.99181419 14451752.99181419 14451752.99181419\n",
      "  14451752.99181419 14451752.99181419]\n",
      " [ 8434967.01225689  8434967.01225689  8434967.01225689  8434967.01225689\n",
      "   8434967.01225689  8434967.01225689]\n",
      " [10622335.52458126 10622335.52458126 10622335.52458126 10622335.52458126\n",
      "  10622335.52458126 10622335.52458126]\n",
      " [10208841.6432115  10208841.6432115  10208841.6432115  10208841.6432115\n",
      "  10208841.6432115  10208841.6432115 ]]\n",
      "\n",
      "Gradient matrix for layer 1:\n",
      "[[ 4667940.52091512 14163552.57842771 12784259.25261172  9777894.98842961\n",
      "  12613359.80243156 19473298.95755107 11163224.72130209  9081619.58314463\n",
      "  21697012.95793913]\n",
      " [ 3599145.20039749 10920593.79394833  9857110.45877985  7539098.59389081\n",
      "   9725341.01289456 15014593.73034926  8607236.20976139  7002245.93438114\n",
      "  16729154.90260352]\n",
      " [ 2508346.07955468  7610870.66629994  6869699.05306605  5254211.02746111\n",
      "   6777865.19958469 10464095.00663337  5998626.34054654  4880063.22602457\n",
      "  11659021.17802142]\n",
      " [ 2565073.17868311  7782993.09320903  7025059.63203167  5373036.79565391\n",
      "   6931148.92474124 10700744.07175598  6134287.31405742  4990427.51452213\n",
      "  11922693.90464274]\n",
      " [ 5672012.52061176 17210126.65033608 15534147.92297843 11881115.99775207\n",
      "  15326488.07451971 23661997.19339871 13564429.56072952 11035072.0520601\n",
      "  26364031.11948397]\n",
      " [ 1985030.51713957  6023016.78295121  5436475.60241044  4158026.4055322\n",
      "   5363801.02087925  8280973.70284035  4747134.55370406  3861936.95845556\n",
      "   9226602.75110754]]\n",
      "\n",
      "Gradient matrix for layer 2:\n",
      "[[ 1358021.76479289 16096253.95975088 21837238.04100323 21048912.95602273\n",
      "  19224179.80230326 15690674.60310735 14541856.99172913]\n",
      " [ 1424167.74842243 16880263.89134499 22900877.54032661 22074155.03085871\n",
      "  20160543.50092808 16454929.73681786 15250155.97445178]\n",
      " [  896400.16944466 10624781.6868719  14414278.4656651  13893922.49047072\n",
      "  12689456.44243586 10357067.71243943  9598758.58352978]\n",
      " [ 1003461.57818107 11893750.7630581  16135845.47452576 15553340.86789679\n",
      "  14205019.6129205  11594062.41354387 10745184.75690955]\n",
      " [  896672.53024422 10628009.90361485 14418658.07707282 13898143.99774783\n",
      "  12693311.9866676  10360214.58739484  9601675.05504741]\n",
      " [ 1077733.97871927 12774080.85220466 17330159.24215276 16704539.86521309\n",
      "  15256421.01112465 12452210.71355597 11540502.36893881]\n",
      " [ 1105633.76706019 13104769.27723681 17778792.93499139 17136977.86547521\n",
      "  15651370.90177964 12774566.74031649 11839256.58825358]]\n",
      "\n",
      "Gradient matrix for layer 3:\n",
      "[[  555575.49466178 18727393.81617887 22491693.61916708 22865354.42493725\n",
      "  14630041.15161033 17169592.32100076 27822707.62893306 15363551.72585021]\n",
      " [  506202.15750377 17063112.4757285  20492883.40708258 20833337.41895472\n",
      "  13329886.69671703 15643750.9570895  25350136.50653608 13998211.05371211]\n",
      " [  568244.76689214 19154450.89969321 23004591.3119577  23386773.03075518\n",
      "  14963662.73116529 17561125.49928007 28457173.08056569 15713900.18633887]\n",
      " [  428883.74540663 14456855.7806484  17362756.08375996 17651208.41369566\n",
      "  11293850.97947051 13254290.60944918 21478101.84197333 11860094.02906161]\n",
      " [  523479.78796724 17645508.55512509 21192344.01069715 21544418.35748833\n",
      "  13784860.76794886 16177701.5617887  26215384.28208558 14475996.29059925]]\n",
      "\n",
      "Gradient matrix for layer 4:\n",
      "[[   87140.63656785  4898432.70479115 13521405.6185221  11417835.00653846\n",
      "  10727321.92510049  7277552.68494059]\n",
      " [  138754.7217763   7799812.96744394 21530240.63763569 18180708.58808117\n",
      "  17081199.17121776 11588104.44568031]\n",
      " [   94892.1197777   5334166.48367185 14724184.85853793 12433493.82924091\n",
      "  11681557.04506487  7924918.0206552 ]\n",
      " [  115995.65851279  6520458.76243298 17998770.84347167 15198641.44373747\n",
      "  14279477.63282445  9687380.64466516]\n",
      " [  121041.50017597  6804100.43409898 18781722.11054948 15859786.34522677\n",
      "  14900638.66671162 10108784.25140959]\n",
      " [   86839.73604453  4881518.19713581 13474715.59895283 11378408.71056493\n",
      "  10690280.00174285  7252422.96937235]\n",
      " [   94526.36195584  5313606.1555953  14667431.08598922 12385569.43223354\n",
      "  11636530.95785394  7894371.7459967 ]\n",
      " [  132210.13338288  7431922.31288358 20514732.39992757 17323186.38713123\n",
      "  16275537.09060065 11041532.96410384]\n",
      " [   65027.67854124  3655397.98455619 10090190.43947848  8520425.5291847\n",
      "   8005138.2366331   5430788.38074341]]\n",
      "\n",
      "Gradient matrix for layer 5:\n",
      "[[   49336.69988196  9190437.66127385 17690844.3415902   8233876.19639306\n",
      "  17903634.33013883 15874290.88290701 15348310.36740635 10982722.57139704\n",
      "  18894594.77121848 14856629.30588432]\n",
      " [   52806.97589155  9836880.47990424 18935194.14315819  8813035.78952959\n",
      "  19162951.48854482 16990866.79803951 16427889.53227335 11755232.25994059\n",
      "  20223614.73206902 15901624.29717961]\n",
      " [   47249.71768269  8801674.73533019 16942507.35676621  7885576.59196226\n",
      "  17146296.15716596 15202795.57459061 14699064.45914377 10518144.54812454\n",
      "  18095338.17229384 14228181.90310684]\n",
      " [   52808.97820661  9837253.47104    18935912.12073083  8813369.95890731\n",
      "  19163678.10213486 16991511.05133888 16428512.4388124  11755677.99041793\n",
      "  20224381.56348917 15902227.24899133]]\n",
      "\n",
      "Gradient matrix for layer 6:\n",
      "[[2.70244897e+04 2.74652120e+07 3.61639504e+07 4.88012875e+07\n",
      "  3.84252987e+07]\n",
      " [4.09576117e+04 4.16255590e+07 5.48091401e+07 7.39619585e+07\n",
      "  5.82363806e+07]\n",
      " [3.31618028e+04 3.37026140e+07 4.43768525e+07 5.98841529e+07\n",
      "  4.71517573e+07]]\n",
      "\n",
      "Gradient matrix for layer 7:\n",
      "[[3.07124484e+04 1.14485726e+08 5.54876835e+07 9.86558452e+07]\n",
      " [3.05344536e+04 1.13822222e+08 5.51661034e+07 9.80840829e+07]]\n",
      "\n",
      "Gradient matrix for layer 8:\n",
      "[[7.91906530e+03 1.83119857e+07 5.45329276e+07]\n",
      " [1.44073652e+04 3.33154805e+07 9.92131991e+07]\n",
      " [7.22807148e+03 1.67141369e+07 4.97745484e+07]\n",
      " [1.56991698e+04 3.63026397e+07 1.08108932e+08]]\n",
      "\n",
      "Gradient matrix for layer 9:\n",
      "[[1.67721255e+04 5.87682472e+07 1.11773492e+08 3.53528035e+07\n",
      "  1.52042839e+08]]\n"
     ]
    }
   ],
   "source": [
    "dim_layer = np.array([\n",
    "    5,   # input size\n",
    "    8,   # layer 1\n",
    "    6,   # layer 2\n",
    "    7,   # layer 3\n",
    "    5,   # layer 4\n",
    "    9,   # layer 5\n",
    "    4,   # layer 6\n",
    "    3,   # layer 7\n",
    "    2,   # layer 8\n",
    "    4,   # layer 9\n",
    "    1    # layer 10 (output)\n",
    "])\n",
    "\n",
    "testNet = FNN(dim_layer, identity, method_ini=\"Random\")\n",
    "\n",
    "inputVect = np.ones((5, 1))      # simple constant input\n",
    "targetVect = np.array([[0.7]])   # single output neuron\n",
    "\n",
    "grads = backwards(testNet, inputVect, targetVect, MeanSquaredErrorDerivative)\n",
    "\n",
    "print(\"=== Gradients for Deep 10-Layer Network ===\")\n",
    "for i, g in enumerate(grads):\n",
    "    print(f\"\\nGradient matrix for layer {i}:\")\n",
    "    print(g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
