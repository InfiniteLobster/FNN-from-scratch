{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c419d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from FNN import FNN\n",
    "from Layer import Layer\n",
    "from Neuron import Neuron\n",
    "\n",
    "from ActivFunctions import *\n",
    "from InitFunctions import *\n",
    "from SuppFunctions import *\n",
    "\n",
    "from LossFunctions import MeanSquaredError, MeanSquaredErrorDerivative\n",
    "from TrainingFunctions import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ea47f5",
   "metadata": {},
   "source": [
    "Neuron Class functionality testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f675aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTest = np.array([1.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb8c9de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.]]), array([[0.]])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zero initialization\n",
    "t0NeuronZero = Neuron(2,identity)\n",
    "print(t0NeuronZero.weight_vector.shape)\n",
    "t0NeuronZero.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ef7148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.70627357]]), array([[0.70627357]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random initialization\n",
    "t0NeuronRandom = Neuron(2,identity,method_ini=\"Random\")\n",
    "print(t0NeuronRandom.weight_vector.shape)\n",
    "t0NeuronRandom.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9f0a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  2.  3.5]\n",
      "(3,)\n",
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[6.5]]), array([[6.5]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization from vector\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "print(vector)\n",
    "print(vector.shape)\n",
    "t1Neuron = Neuron(vector,identity)\n",
    "print(t1Neuron.weight_vector.shape)\n",
    "t1Neuron.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7a43849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  2.  3.5]]\n",
      "(1, 3)\n",
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[6.5]]), array([[6.5]])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization from row vector(2D array)\n",
    "vector_row = vector[np.newaxis,:]\n",
    "print(vector_row)\n",
    "print(vector_row.shape)\n",
    "t2Neuron = Neuron(vector_row,identity)\n",
    "print(t2Neuron.weight_vector.shape)\n",
    "t2Neuron.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6193892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. ]\n",
      " [2. ]\n",
      " [3.5]]\n",
      "(3, 1)\n",
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[6.5]]), array([[6.5]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization from column vector(2D array)\n",
    "vector_column = vector[:,np.newaxis]\n",
    "print(vector_column)\n",
    "print(vector_column.shape)\n",
    "t3Neuron = Neuron(vector_column,identity)\n",
    "print(t3Neuron.weight_vector.shape)\n",
    "t3Neuron.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88aceccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "(1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.62823325, 0.62823325]]), array([[0.62823325, 0.62823325]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#array input\n",
    "t0NeuronRandom = Neuron(2,identity,method_ini=\"Random\")\n",
    "inputTest = np.array([[1.0,1.0],[1.0,1.0]])\n",
    "print(inputTest.shape)\n",
    "print(inputTest)\n",
    "print(t0NeuronRandom.weight_vector.shape)\n",
    "t0NeuronRandom.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b62878a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#wrong activ function\u001b[39;00m\n\u001b[32m      2\u001b[39m vector = np.array([\u001b[32m1.0\u001b[39m,\u001b[32m2.0\u001b[39m,\u001b[32m3.5\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m errorNeuron = \u001b[43mNeuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Normal\\Documents\\DTU\\Deep learning\\Project\\code\\FNN-from-scratch\\Neuron.py:16\u001b[39m, in \u001b[36mNeuron.__init__\u001b[39m\u001b[34m(self, weights, activ_function, method_ini, datatype_weights, random_lower_bound, random_upper_bound)\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mself\u001b[39m.activ_function = activ_function\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\u001b[38;5;66;03m#if given variable is not an activation function, then class object can not be initialized due to lack (no activ function) or too much (e.g. vector of activ functions) of information. TO DO: implementing proper error\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m#based on the input (weights) the weight vector of the object would be assigned (or created, initialized). The choice of method is based on the data type of input\u001b[39;00m\n\u001b[32m     18\u001b[39m type_weights = \u001b[38;5;28mtype\u001b[39m(weights)\n",
      "\u001b[31mNotImplementedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#wrong activ function\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "errorNeuron = Neuron(vector,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ac2513",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#wrong input function\u001b[39;00m\n\u001b[32m      2\u001b[39m vector = np.array([\u001b[33m\"\u001b[39m\u001b[33m1.0\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m2.0\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m3.5\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m errorNeuron = \u001b[43mNeuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\u001b[43midentity\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Normal\\Documents\\DTU\\Deep learning\\Project\\code\\FNN-from-scratch\\Neuron.py:52\u001b[39m, in \u001b[36mNeuron.__init__\u001b[39m\u001b[34m(self, weights, activ_function, method_ini, datatype_weights, random_lower_bound, random_upper_bound)\u001b[39m\n\u001b[32m     50\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\u001b[38;5;66;03m#given variable is of unappropriate datatype. Error should be thrown. TO DO: error implementation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\u001b[38;5;66;03m#given variable is of type for which object initialization is not implemented. Appropriate error sould be passed. TO DO: implementing proper error\u001b[39;00m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[31mNotImplementedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#wrong input function\n",
    "vector = np.array([\"1.0\",\"2.0\",\"3.5\"])\n",
    "errorNeuron = Neuron(vector,identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af6baa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m neuronTest = Neuron(vector,identity)\n\u001b[32m      4\u001b[39m inputTestErrorSmall = np.array([\u001b[32m1.0\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mneuronTest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputTestErrorSmall\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Normal\\Documents\\DTU\\Deep learning\\Project\\code\\FNN-from-scratch\\Neuron.py:94\u001b[39m, in \u001b[36mNeuron.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     92\u001b[39m     output = [matrix_multi,activation_out]\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\u001b[38;5;66;03m#if inproper input was given and operation cannot proceed proper error should be raised. TO DO: implement proper error\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m#results are returned\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[31mNotImplementedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#wrong input (too small)\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "neuronTest = Neuron(vector,identity)\n",
    "inputTestErrorSmall = np.array([1.0])\n",
    "neuronTest.forward(inputTestErrorSmall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c63967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m inputTestErrorBig = np.array([[\u001b[32m1.0\u001b[39m],[\u001b[32m1.0\u001b[39m],[\u001b[32m1.0\u001b[39m],[\u001b[32m1.0\u001b[39m]])\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(inputTestErrorBig)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mneuronTest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputTestErrorBig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Normal\\Documents\\DTU\\Deep learning\\Project\\code\\FNN-from-scratch\\Neuron.py:94\u001b[39m, in \u001b[36mNeuron.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     92\u001b[39m     output = [matrix_multi,activation_out]\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\u001b[38;5;66;03m#if inproper input was given and operation cannot proceed proper error should be raised. TO DO: implement proper error\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m#results are returned\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[31mNotImplementedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#wrong input (too big)\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "neuronTest = Neuron(vector,identity)\n",
    "inputTestErrorBig = np.array([[1.0],[1.0],[1.0],[1.0]])\n",
    "print(inputTestErrorBig)\n",
    "neuronTest.forward(inputTestErrorBig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68632b0b",
   "metadata": {},
   "source": [
    "Layer class implementation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61504054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function ActivFunctions.identity(x)>,\n",
       " <function ActivFunctions.identity(x)>,\n",
       " <function ActivFunctions.identity(x)>,\n",
       " <function ActivFunctions.identity(x)>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization by number of dim in vector\n",
    "dim_layer = np.array([4,5])\n",
    "testLayer = Layer(dim_layer,identity,method_ini=\"Random\")\n",
    "testLayer.weights_array\n",
    "testLayer.activ_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637ade70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[2.93741261],\n",
      "       [3.16570166],\n",
      "       [4.12556719],\n",
      "       [3.06488001]]), array([[2.93741261],\n",
      "       [3.16570166],\n",
      "       [4.12556719],\n",
      "       [3.06488001]])]\n",
      "[array([[2.93741261, 4.92025167],\n",
      "       [3.16570166, 6.10149423],\n",
      "       [4.12556719, 7.70806968],\n",
      "       [3.06488001, 5.19384362]]), array([[2.93741261, 4.92025167],\n",
      "       [3.16570166, 6.10149423],\n",
      "       [4.12556719, 7.70806968],\n",
      "       [3.06488001, 5.19384362]])]\n"
     ]
    }
   ],
   "source": [
    "#forward test pass\n",
    "inputTestVect = np.array([[1.0],[1.0],[1.0],[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "\n",
    "print(testLayer.forward(inputTestVect))\n",
    "print(testLayer.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0fad2d",
   "metadata": {},
   "source": [
    "FNN class implementation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "000a08cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28156461 0.66980571 0.61900519 0.09558239 0.64158846 0.83980218]\n",
      " [0.67968198 0.37002793 0.91374895 0.57998655 0.41853405 0.85563371]\n",
      " [0.07669919 0.91433914 0.37862469 0.13313974 0.29647039 0.08852724]\n",
      " [0.95751846 0.68891225 0.68969802 0.88200442 0.59904858 0.15260945]\n",
      " [0.27435503 0.18519506 0.66283938 0.40497699 0.09623416 0.12438847]]\n",
      "[[0.68030577 0.49412327 0.96877788 0.96247331 0.6735594  0.11385461]\n",
      " [0.00288413 0.41420213 0.28138484 0.10421633 0.28902314 0.64024188]\n",
      " [0.00594837 0.69361562 0.81496139 0.91313827 0.5032143  0.55503246]]\n",
      "[[0.34204032 0.32508896 0.88554357 0.15301817]\n",
      " [0.29299083 0.54682188 0.0127216  0.27421699]]\n",
      "[[0.46546055 0.19271379 0.14741595]]\n",
      "[<function identity at 0x00000140650BA5C0>, <function identity at 0x00000140650BA5C0>, <function identity at 0x00000140650BA5C0>, <function identity at 0x00000140650BA5C0>, <function identity at 0x00000140650BA5C0>]\n",
      "[<function identity at 0x00000140650BA5C0>, <function identity at 0x00000140650BA5C0>, <function identity at 0x00000140650BA5C0>]\n",
      "[<function identity at 0x00000140650BA5C0>, <function identity at 0x00000140650BA5C0>]\n",
      "[<function identity at 0x00000140650BA5C0>]\n",
      "[[array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]]), array([[3.14734854],\n",
      "       [3.81761316],\n",
      "       [1.88780038],\n",
      "       [3.96979118],\n",
      "       [1.7479891 ]]), array([[10.62376736],\n",
      "       [ 4.84397803],\n",
      "       [ 9.99187494]]), array([[9.61420176],\n",
      "       [8.90386432]]), array([[3.63082139]])], [array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]]), array([[3.14734854],\n",
      "       [3.81761316],\n",
      "       [1.88780038],\n",
      "       [3.96979118],\n",
      "       [1.7479891 ]]), array([[10.62376736],\n",
      "       [ 4.84397803],\n",
      "       [ 9.99187494]]), array([[9.61420176],\n",
      "       [8.90386432]]), array([[3.63082139]])]]\n",
      "[[array([[1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.]]), array([[3.14734854, 6.01313248],\n",
      "       [3.81761316, 6.95554434],\n",
      "       [1.88780038, 3.69890157],\n",
      "       [3.96979118, 6.9820639 ],\n",
      "       [1.7479891 , 3.22162316]]), array([[10.62376736, 19.0196374 ],\n",
      "       [ 4.84397803,  8.91680319],\n",
      "       [ 9.99187494, 18.52443945]]), array([[ 9.61420176, 17.2559079 ],\n",
      "       [ 8.90386432, 15.8864968 ]]), array([[3.63082139, 6.13283491]])], [array([[1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.]]), array([[3.14734854, 6.01313248],\n",
      "       [3.81761316, 6.95554434],\n",
      "       [1.88780038, 3.69890157],\n",
      "       [3.96979118, 6.9820639 ],\n",
      "       [1.7479891 , 3.22162316]]), array([[10.62376736, 19.0196374 ],\n",
      "       [ 4.84397803,  8.91680319],\n",
      "       [ 9.99187494, 18.52443945]]), array([[ 9.61420176, 17.2559079 ],\n",
      "       [ 8.90386432, 15.8864968 ]]), array([[3.63082139, 6.13283491]])]]\n"
     ]
    }
   ],
   "source": [
    "#initialization by number of dim in vector\n",
    "dim_layer = np.array([5,5,3,2,1])\n",
    "testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "print(testNet.weights_list[0])\n",
    "print(testNet.weights_list[1])\n",
    "print(testNet.weights_list[2])\n",
    "print(testNet.weights_list[3])\n",
    "print(testNet.activ_functions_list[0])\n",
    "print(testNet.activ_functions_list[1])\n",
    "print(testNet.activ_functions_list[2])\n",
    "print(testNet.activ_functions_list[3])\n",
    "#forward test pass\n",
    "inputTestVect = np.array([[1.0],[1.0],[1.0],[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "\n",
    "print(testNet.forward(inputTestVect))\n",
    "print(testNet.forward(inputTestArray))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35a311f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient matrix of the single layer:\n",
      "[[1.07052156 1.07052156 1.07052156 1.07052156 1.07052156]\n",
      " [2.1845486  2.1845486  2.1845486  2.1845486  2.1845486 ]\n",
      " [1.57729857 1.57729857 1.57729857 1.57729857 1.57729857]\n",
      " [2.53354445 2.53354445 2.53354445 2.53354445 2.53354445]\n",
      " [2.36844568 2.36844568 2.36844568 2.36844568 2.36844568]]\n"
     ]
    }
   ],
   "source": [
    "dim_layer = np.array([4, 5])\n",
    "testNet = FNN(dim_layer, identity, method_ini=\"Random\")\n",
    "\n",
    "inputTestVect = np.array([[1.0],\n",
    "                          [1.0],\n",
    "                          [1.0],\n",
    "                          [1.0]])\n",
    "\n",
    "targetVect = np.array([[0.5],\n",
    "                       [0.5],\n",
    "                       [0.5],\n",
    "                       [0.5],\n",
    "                       [0.5]])\n",
    "\n",
    "grads = backwards(testNet, inputTestVect, targetVect, MeanSquaredErrorDerivative)\n",
    "\n",
    "print(\"Gradient matrix of the single layer:\")\n",
    "print(grads[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "679decc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Gradients for Deep 10-Layer Network ===\n",
      "\n",
      "Gradient matrix for layer 0:\n",
      "[[ 985404.49920458  985404.49920458  985404.49920458  985404.49920458\n",
      "   985404.49920458  985404.49920458]\n",
      " [ 545004.28472631  545004.28472631  545004.28472631  545004.28472631\n",
      "   545004.28472631  545004.28472631]\n",
      " [1182509.02828762 1182509.02828762 1182509.02828762 1182509.02828762\n",
      "  1182509.02828762 1182509.02828762]\n",
      " [1011603.42491186 1011603.42491186 1011603.42491186 1011603.42491186\n",
      "  1011603.42491186 1011603.42491186]\n",
      " [ 733498.95513599  733498.95513599  733498.95513599  733498.95513599\n",
      "   733498.95513599  733498.95513599]\n",
      " [ 705173.35808653  705173.35808653  705173.35808653  705173.35808653\n",
      "   705173.35808653  705173.35808653]\n",
      " [1005335.4371138  1005335.4371138  1005335.4371138  1005335.4371138\n",
      "  1005335.4371138  1005335.4371138 ]\n",
      " [ 921961.57656401  921961.57656401  921961.57656401  921961.57656401\n",
      "   921961.57656401  921961.57656401]]\n",
      "\n",
      "Gradient matrix for layer 1:\n",
      "[[ 304050.26855084  818692.12662587  914655.63847057  709042.72668205\n",
      "   960321.21740177  938896.50582588  837292.31539114  944047.5362179\n",
      "   798196.55465916]\n",
      " [ 213987.96711807  576188.48589488  643726.78117425  499018.18013746\n",
      "   675865.82334426  660787.2953822   589279.13896637  664412.54632312\n",
      "   561763.87840816]\n",
      " [ 411586.93512301 1108247.60923024 1238151.54883882  959817.34907606\n",
      "  1299968.15489707 1270965.93952182 1133426.32301035 1277938.78918211\n",
      "  1080503.15207329]\n",
      " [ 288998.47914458  778163.36295377  869376.27030844  673942.07752649\n",
      "   912781.20766723  892417.11099646  795842.76277994  897313.14334143\n",
      "   758682.40950548]\n",
      " [ 355484.99018605  957186.33627956 1069383.53389732  828988.0746937\n",
      "  1122774.13919285 1097725.11219941  978933.02952274 1103747.51762955\n",
      "   933223.62697439]\n",
      " [ 227483.09926312  612525.76159467  684323.3534687   530488.71735706\n",
      "   718489.24147935  702459.78749027  626441.97553971  706313.66455988\n",
      "   597191.46751764]]\n",
      "\n",
      "Gradient matrix for layer 2:\n",
      "[[  54727.38494003  701906.21189026  697901.94954506  512384.39452779\n",
      "   476745.29522571  605400.78972659  911311.03771322]\n",
      " [  70649.52102274  906115.60788567  900946.3636938   661455.1762811\n",
      "   615447.39976973  781533.33779491 1176443.71986202]\n",
      " [  79016.92702429 1013431.79440416 1007650.32858292  739794.90076399\n",
      "   688338.17371868  874094.57029031 1315776.3310327 ]\n",
      " [ 102716.63613762 1317392.47268004 1309876.95994795  961683.10386055\n",
      "   894792.85505195 1136263.54893275 1710419.82677501]\n",
      " [  75206.04246546  964555.28500085  959052.65182542  704115.54609664\n",
      "   655140.51068286  831938.11563783 1252318.13426853]\n",
      " [  87502.77955884 1122267.11722685 1115864.76334731  819243.5792955\n",
      "   762260.76797861  967966.07230988 1457081.2935779 ]\n",
      " [ 121465.25267855 1557852.90083401 1548965.59993185 1137216.77032541\n",
      "  1058117.20789053 1343662.95733856 2022618.57726023]]\n",
      "\n",
      "Gradient matrix for layer 3:\n",
      "[[  39732.24950574 1842572.22130018 1459630.2158525  1322172.32744602\n",
      "  1744675.35135199 1411814.69563662 1163336.48280541 1140735.97375053]\n",
      " [  41854.16372049 1940975.4135865  1537582.26089966 1392783.38750071\n",
      "  1837850.3282086  1487213.13666454 1225464.86088896 1201657.36400881]\n",
      " [  21324.93987139  988938.2634184   783407.10568166  709631.237424\n",
      "   936395.43256407  757743.74389855  624381.47486292  612251.41671989]\n",
      " [  35921.88284116 1665867.50771208 1319650.06405429 1195374.53915059\n",
      "  1577359.05584888 1276420.10510279 1051771.22765591 1031338.13241164]\n",
      " [  37983.21873653 1761461.39697874 1395376.66386486 1263969.73102434\n",
      "  1667873.98949188 1349666.0034831  1112125.90880849 1090520.28391519]]\n",
      "\n",
      "Gradient matrix for layer 4:\n",
      "[[   8562.85730028  775904.43729351 1093388.57107323  870629.95106782\n",
      "   863304.1336047  1434102.46110845]\n",
      " [   5351.561785    484919.97353441  683339.2508968   544120.94136583\n",
      "   539542.49711472  896276.51816518]\n",
      " [  10249.26101886  928714.19254611 1308724.93456214 1042095.33178188\n",
      "  1033326.73822449 1716540.39490035]\n",
      " [   8655.00544299  784254.23810361 1105154.93860214  879999.12892184\n",
      "   872594.47556908 1449535.37954014]\n",
      " [   7424.70615843  672773.38064969  948058.40767012  754908.24297631\n",
      "   748556.15276546 1243485.55644746]\n",
      " [   6345.51444563  574984.80269126  810256.75532463  645181.24471361\n",
      "   639752.43994574 1062743.14336416]\n",
      " [   9763.13598062  884665.04387683 1246651.78043958  992668.4870479\n",
      "   984315.79009716 1635124.4505133 ]\n",
      " [  10458.44658373  947669.08135365 1335435.77392842 1063364.30914792\n",
      "  1054416.75018092 1751574.67410069]\n",
      " [   8990.4180922   814646.91588796 1147983.67489553  914102.26624183\n",
      "   906410.655889   1505710.09889379]]\n",
      "\n",
      "Gradient matrix for layer 5:\n",
      "[[   4775.65029864 1529364.78880274 1975074.72710081  828876.12330835\n",
      "  1139961.53410545 1336920.62806116 1677755.44565382 1717681.4397174\n",
      "  1274862.39029935  914478.85019347]\n",
      " [   3337.04345635 1068662.15943544 1380107.37422709  579187.2248691\n",
      "   796561.92141324  934189.4725431  1172351.92720803 1200250.69887191\n",
      "   890825.52767995  639003.16651781]\n",
      " [   4315.3558337  1381959.07373955 1784709.8745927   748986.04178586\n",
      "  1030087.91447615 1208063.37791068 1516047.3018686  1552125.08408132\n",
      "  1151986.53777213  826338.06794853]\n",
      " [   2921.42847017  935564.69923315 1208220.69826102  507051.84706886\n",
      "   697353.42254586  817840.03034998 1026340.33449187 1050764.42931944\n",
      "   779876.88580026  559417.96012323]]\n",
      "\n",
      "Gradient matrix for layer 6:\n",
      "[[2.60709631e+03 3.52320485e+06 2.57569972e+06 3.96823148e+06\n",
      "  4.30180025e+06]\n",
      " [1.67355216e+03 2.26162227e+06 1.65339800e+06 2.54729460e+06\n",
      "  2.76141969e+06]\n",
      " [1.59733769e+03 2.15862678e+06 1.57810136e+06 2.43128944e+06\n",
      "  2.63566316e+06]]\n",
      "\n",
      "Gradient matrix for layer 7:\n",
      "[[1.65632506e+03 5.90959277e+06 6.21137376e+06 5.76931679e+06]\n",
      " [3.27519404e+03 1.16855462e+07 1.22822837e+07 1.14081665e+07]]\n",
      "\n",
      "Gradient matrix for layer 8:\n",
      "[[1.33549986e+03 8.54654737e+06 4.29944260e+06]\n",
      " [2.33132754e+03 1.49193585e+07 7.50536125e+06]\n",
      " [8.93721400e+02 5.71938080e+06 2.87720273e+06]\n",
      " [1.48005879e+03 9.47165397e+06 4.76482851e+06]]\n",
      "\n",
      "Gradient matrix for layer 9:\n",
      "[[4.59864480e+03 6.76966515e+06 1.82523912e+07 2.55233882e+07\n",
      "  1.54330734e+07]]\n"
     ]
    }
   ],
   "source": [
    "dim_layer = np.array([\n",
    "    5,   # input size\n",
    "    8,   # layer 1\n",
    "    6,   # layer 2\n",
    "    7,   # layer 3\n",
    "    5,   # layer 4\n",
    "    9,   # layer 5\n",
    "    4,   # layer 6\n",
    "    3,   # layer 7\n",
    "    2,   # layer 8\n",
    "    4,   # layer 9\n",
    "    1    # layer 10 (output)\n",
    "])\n",
    "\n",
    "testNet = FNN(dim_layer, identity, method_ini=\"Random\")\n",
    "\n",
    "inputVect = np.ones((5, 1))      # simple constant input\n",
    "targetVect = np.array([[0.7]])   # single output neuron\n",
    "\n",
    "grads = backwards(testNet, inputVect, targetVect, MeanSquaredErrorDerivative)\n",
    "\n",
    "print(\"=== Gradients for Deep 10-Layer Network ===\")\n",
    "for i, g in enumerate(grads):\n",
    "    print(f\"\\nGradient matrix for layer {i}:\")\n",
    "    print(g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
