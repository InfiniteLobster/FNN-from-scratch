{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c419d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FNN import FNN\n",
    "from Layer import Layer\n",
    "from Neuron import Neuron\n",
    "import numpy as np\n",
    "from ActivFunctions import  *\n",
    "from InitFunctions import  *\n",
    "from SuppFunctions import  *\n",
    "from ErrorClasses import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ea47f5",
   "metadata": {},
   "source": [
    "Neuron Class functionality testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f675aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTest = np.array([1.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c9de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero initialization\n",
    "t0NeuronZero = Neuron(2,identity)\n",
    "print(t0NeuronZero.weight_vector.shape)\n",
    "t0NeuronZero.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef7148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random initialization\n",
    "t0NeuronRandom = Neuron(2,identity,method_ini=\"Random\")\n",
    "print(t0NeuronRandom.weight_vector.shape)\n",
    "t0NeuronRandom.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe12c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization from list\n",
    "vector = [1.0,2.0,3.5]\n",
    "print(vector)\n",
    "tNeuron = Neuron(vector,identity)\n",
    "print(tNeuron.weight_vector.shape)\n",
    "tNeuron.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization from vector\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "print(vector)\n",
    "print(vector.shape)\n",
    "t1Neuron = Neuron(vector,identity)\n",
    "print(t1Neuron.weight_vector.shape)\n",
    "t1Neuron.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a43849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization from row vector(2D array)\n",
    "vector_row = vector[np.newaxis,:]\n",
    "print(vector_row)\n",
    "print(vector_row.shape)\n",
    "t2Neuron = Neuron(vector_row,identity)\n",
    "print(t2Neuron.weight_vector.shape)\n",
    "t2Neuron.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6193892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization from column vector(2D array)\n",
    "vector_column = vector[:,np.newaxis]\n",
    "print(vector_column)\n",
    "print(vector_column.shape)\n",
    "t3Neuron = Neuron(vector_column,identity)\n",
    "print(t3Neuron.weight_vector.shape)\n",
    "t3Neuron.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aceccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array input\n",
    "t0NeuronRandom = Neuron(2,identity,method_ini=\"Random\")\n",
    "inputTest = np.array([[1.0,1.0],[1.0,1.0]])\n",
    "print(inputTest.shape)\n",
    "print(inputTest)\n",
    "print(t0NeuronRandom.weight_vector.shape)\n",
    "t0NeuronRandom.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce592a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list input\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "inputTest = [\"1.0\",\"1.0\"]\n",
    "t0NeuronRandom.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62878a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#error messages testing\n",
    "print(\"Test for: no function given as activation function\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    errorNeuron = Neuron(vector,1)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not vector given for weights initialization (2 dim)\")\n",
    "try:\n",
    "    vector = np.array([[1.0,2.0,3.5],[1.0,2.0,3.5]])\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not vector given for weights initialization (higher than 2 dim)\")\n",
    "try:\n",
    "    vector = np.array([[[1.0,2.0,3.5],[1.0,2.0,3.5]],[[1.0,2.0,3.5],[1.0,2.0,3.5]]])\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong weights given for initialization\")\n",
    "try:\n",
    "    vector = np.array([\"1.0\",\"2.0\",\"3.5\"])\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong var type given in list for weight initialization\")\n",
    "try:\n",
    "    vector = [\"as\",\"2.0\",\"3.5\"]\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - inproper dimension of input\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = np.array([[[1.0,1.0],[1.0,1.0]],[[1.0,1.0],[1.0,1.0]]]) \n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedArrayDimGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - wrong value types in input: they are not rational numbers\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = np.array([1.0 + 3j,1.0]) \n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given variable is of not supported type for list\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = [\"a\",\"1.0\"]\n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given variable is of not supported type\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = \"a\"\n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given input is too small to match neuron dimensions\")\n",
    "try:\n",
    "    #wrong input (too small)\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    neuronTest = Neuron(vector,identity)\n",
    "    inputTestErrorSmall = np.array([1.0])\n",
    "    neuronTest.forward(inputTestErrorSmall)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given input is too small to match neuron dimensions\")\n",
    "try:\n",
    "    #wrong input (too big)\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    neuronTest = Neuron(vector,identity)\n",
    "    inputTestErrorBig = np.array([[1.0],[1.0],[1.0],[1.0]])\n",
    "    neuronTest.forward(inputTestErrorBig)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68632b0b",
   "metadata": {},
   "source": [
    "Layer class implementation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61504054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization by number of dim in vector\n",
    "dim_layer = np.array([4,5])\n",
    "testLayer = Layer(dim_layer,identity,method_ini=\"Random\")\n",
    "testLayer.weights_array\n",
    "testLayer.activ_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637ade70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward test pass\n",
    "inputTestVect = np.array([[1.0],[1.0],[1.0],[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "\n",
    "print(testLayer.forward(inputTestVect))\n",
    "print(testLayer.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0fad2d",
   "metadata": {},
   "source": [
    "FNN class implementation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization by number of dim in vector\n",
    "dim_layer = np.array([5,5,3,2,1])\n",
    "testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "print(testNet.weights_list[0])\n",
    "print(testNet.weights_list[1])\n",
    "print(testNet.weights_list[2])\n",
    "print(testNet.weights_list[3])\n",
    "print(testNet.activ_functions_list[0])\n",
    "print(testNet.activ_functions_list[1])\n",
    "print(testNet.activ_functions_list[2])\n",
    "print(testNet.activ_functions_list[3])\n",
    "#forward test pass\n",
    "inputTestVect = np.array([[1.0],[1.0],[1.0],[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "\n",
    "print(testNet.forward(inputTestVect))\n",
    "print(testNet.forward(inputTestArray))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#error messages testing\n",
    "print(\"Test for: not supported input for weights\")\n",
    "try:\n",
    "    dim_layer = \"[5,5,3,2,1]\"\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: array of not supported dimension\")\n",
    "try:\n",
    "    dim_layer = np.array([[5,5,3,2,1],[5,5,3,2,1]])\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedArrayDimGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: given numbers are not integers\")\n",
    "try:\n",
    "    dim_layer = np.array([5,5,3.1,2,1])\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not enough numbers given. Minimally required input and output layers cannot be created\")\n",
    "try:\n",
    "    dim_layer = np.array([5])\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44cceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Reload order:\n",
    "# ActivFunctions → SuppFunctions → InitFunctions → Layer → FNN → TrainingFunctions\n",
    "\n",
    "modules_in_order = [\n",
    "    \"ActivFunctions\",\n",
    "    \"SuppFunctions\",\n",
    "    \"InitFunctions\",\n",
    "    \"Layer\",\n",
    "    \"FNN\",\n",
    "    \"TrainingFunctions\"\n",
    "]\n",
    "\n",
    "for m in modules_in_order:\n",
    "    if m in sys.modules:\n",
    "        importlib.reload(sys.modules[m])\n",
    "    else:\n",
    "        globals()[m] = importlib.import_module(m)\n",
    "\n",
    "print(\"All modules reloaded successfully.\")\n",
    "\n",
    "from FNN import FNN\n",
    "from TrainingFunctions import backwards\n",
    "from LossFunctions import MeanSquaredErrorDerivative\n",
    "\n",
    "# Activations\n",
    "from ActivFunctions import identity, sigmoid, tanh, relu, leaky_relu\n",
    "\n",
    "print(\"=== Test 1: Single-Layer Network Gradient ===\")\n",
    "\n",
    "dim_layer = np.array([4, 5])   # 4 inputs -> 5 outputs\n",
    "testNet = FNN(dim_layer, identity, method_ini=\"Random\")\n",
    "\n",
    "inputTestVect = np.ones((4, 1))\n",
    "targetVect = 0.5 * np.ones((5, 1))\n",
    "\n",
    "grads = backwards(testNet, inputTestVect, targetVect, MeanSquaredErrorDerivative)\n",
    "\n",
    "print(\"\\nGradient matrix for single layer:\")\n",
    "print(grads[0])\n",
    "\n",
    "print(\"=== Test 2: Deep 10-Layer Network ===\")\n",
    "\n",
    "dim_layer = np.array([\n",
    "    5,   # input size\n",
    "    8,\n",
    "    6,\n",
    "    7,\n",
    "    5,\n",
    "    9,\n",
    "    4,\n",
    "    3,\n",
    "    2,\n",
    "    4,\n",
    "    1    # output\n",
    "])\n",
    "\n",
    "deepNet = FNN(dim_layer, identity, method_ini=\"Random\")\n",
    "\n",
    "inputVect = np.ones((5, 1))\n",
    "targetVect = np.array([[0.7]])\n",
    "\n",
    "grads = backwards(deepNet, inputVect, targetVect, MeanSquaredErrorDerivative)\n",
    "\n",
    "for i, g in enumerate(grads):\n",
    "    print(f\"\\nGradient matrix for layer {i}:\")\n",
    "    print(g)\n",
    "\n",
    "print(\"=== Test 3: Activation Function Sanity ===\")\n",
    "\n",
    "activations = [identity, sigmoid, tanh, relu, leaky_relu]\n",
    "x = np.linspace(-3, 3, 7).reshape(-1,1)\n",
    "\n",
    "for act in activations:\n",
    "    out = act(x)\n",
    "    print(f\"\\nActivation: {act.__name__}\")\n",
    "    print(\"Input:\\n\", x.T)\n",
    "    print(\"Output:\\n\", out.T)\n",
    "\n",
    "print(\"=== Test 4: Backprop With ReLU Hidden Layers ===\")\n",
    "\n",
    "dim_layer = np.array([3, 4, 2])   # Small net\n",
    "testNet = FNN(dim_layer, relu, method_ini=\"Random\")\n",
    "\n",
    "inputVect = np.ones((3, 1))\n",
    "targetVect = np.array([[0.2], [0.8]])\n",
    "\n",
    "grads = backwards(testNet, inputVect, targetVect, MeanSquaredErrorDerivative)\n",
    "\n",
    "for i, g in enumerate(grads):\n",
    "    print(f\"\\nReLU Net - Gradient for layer {i}:\")\n",
    "    print(g)\n",
    "\n",
    "print(\"=== Test 5: Randomized Gradient Stability ===\")\n",
    "\n",
    "for run in range(3):\n",
    "    dim_layer = np.array([4, 6, 5, 3])\n",
    "    net = FNN(dim_layer, tanh, method_ini=\"Random\")\n",
    "\n",
    "    x = np.random.randn(4, 1)\n",
    "    y = np.random.randn(3, 1)\n",
    "\n",
    "    grads = backwards(net, x, y, MeanSquaredErrorDerivative)\n",
    "    \n",
    "    print(f\"\\nRun {run+1} — Max gradient magnitude across layers:\")\n",
    "    for i, g in enumerate(grads):\n",
    "        print(f\"  Layer {i}: {np.max(np.abs(g)):.4f}\")\n",
    "\n",
    "print(\"=== Test 6: Numerical Gradient Check (Finite Difference) ===\")\n",
    "\n",
    "eps = 1e-5\n",
    "\n",
    "dim_layer = np.array([3, 4, 2])\n",
    "net = FNN(dim_layer, sigmoid, method_ini=\"Random\")\n",
    "\n",
    "x = np.random.randn(3, 1)\n",
    "y = np.random.randn(2, 1)\n",
    "\n",
    "# Analytical gradients\n",
    "grads_analytical = backwards(net, x, y, MeanSquaredErrorDerivative)\n",
    "\n",
    "# Numeric gradient for layer 0\n",
    "W = net.weights_list[0]\n",
    "num_grad = np.zeros_like(W)\n",
    "\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(W.shape[1]):\n",
    "        orig = W[i, j]\n",
    "\n",
    "        W[i, j] = orig + eps\n",
    "        plus = net.forward(x)[1][-1]\n",
    "        L_plus = 0.5 * np.sum((plus - y) ** 2)\n",
    "\n",
    "        W[i, j] = orig - eps\n",
    "        minus = net.forward(x)[1][-1]\n",
    "        L_minus = 0.5 * np.sum((minus - y) ** 2)\n",
    "\n",
    "        num_grad[i, j] = (L_plus - L_minus) / (2 * eps)\n",
    "        W[i, j] = orig  # restore\n",
    "\n",
    "print(\"\\nAnalytical vs Numerical (Layer 0):\")\n",
    "print(\"Analytical:\\n\", grads_analytical[0])\n",
    "print(\"Numerical:\\n\", num_grad)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02452",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
