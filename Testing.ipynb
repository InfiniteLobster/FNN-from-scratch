{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c419d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FNN import FNN\n",
    "from Layer import Layer\n",
    "from Neuron import Neuron\n",
    "import numpy as np\n",
    "from ActivFunctions import  *\n",
    "from InitFunctions import  *\n",
    "from SuppFunctions import  *\n",
    "from ErrorClasses import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ea47f5",
   "metadata": {},
   "source": [
    "Neuron Class functionality testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb8c9de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "[array([[0.]]), array([[0.]])]\n",
      "[array([[0.]]), array([[0.]])]\n",
      "[array([[0.]]), array([[0.]])]\n",
      "[array([[0.]]), array([[0.]])]\n",
      "[array([[0., 0.]]), array([[0., 0.]])]\n"
     ]
    }
   ],
   "source": [
    "#inputs\n",
    "inputTestList = [1.0,1.0]\n",
    "inputTestVect1D = np.array([1.0,1.0])\n",
    "inputTestVect2Drow = np.array([[1.0,1.0]])\n",
    "inputTestVect2Dcol = np.array([[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0]])\n",
    "#zero initialization\n",
    "neuron = Neuron(2,identity)\n",
    "print(neuron.weight_vector.shape)\n",
    "#forward pass\n",
    "print(neuron.forward(inputTestList))\n",
    "print(neuron.forward(inputTestVect1D))\n",
    "print(neuron.forward(inputTestVect2Drow))\n",
    "print(neuron.forward(inputTestVect2Dcol))\n",
    "print(neuron.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42ef7148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.96322682]]), array([[0.96322682]])]\n",
      "[array([[0.96322682]]), array([[0.96322682]])]\n",
      "[array([[0.96322682]]), array([[0.96322682]])]\n",
      "[array([[0.96322682]]), array([[0.96322682]])]\n",
      "[array([[0.96322682, 1.68628508]]), array([[0.96322682, 1.68628508]])]\n"
     ]
    }
   ],
   "source": [
    "#inputs\n",
    "inputTestList = [1.0,1.0]\n",
    "inputTestVect1D = np.array([1.0,1.0])\n",
    "inputTestVect2Drow = np.array([[1.0,1.0]])\n",
    "inputTestVect2Dcol = np.array([[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0]])\n",
    "#random initialization\n",
    "neuron = Neuron(2,identity,method_ini=\"Random\")\n",
    "#forward pass\n",
    "print(neuron.forward(inputTestList))\n",
    "print(neuron.forward(inputTestVect1D))\n",
    "print(neuron.forward(inputTestVect2Drow))\n",
    "print(neuron.forward(inputTestVect2Dcol))\n",
    "print(neuron.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbe12c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[ 6.5, 12. ]]), array([[ 6.5, 12. ]])]\n"
     ]
    }
   ],
   "source": [
    "#inputs\n",
    "inputTestList = [1.0,1.0]\n",
    "inputTestVect1D = np.array([1.0,1.0])\n",
    "inputTestVect2Drow = np.array([[1.0,1.0]])\n",
    "inputTestVect2Dcol = np.array([[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0]])\n",
    "#initialization from list\n",
    "vector = [1.0,2.0,3.5]\n",
    "neuron = Neuron(vector,identity)\n",
    "#forward pass\n",
    "print(neuron.forward(inputTestList))\n",
    "print(neuron.forward(inputTestVect1D))\n",
    "print(neuron.forward(inputTestVect2Drow))\n",
    "print(neuron.forward(inputTestVect2Dcol))\n",
    "print(neuron.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa9f0a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[ 6.5, 12. ]]), array([[ 6.5, 12. ]])]\n"
     ]
    }
   ],
   "source": [
    "#inputs\n",
    "inputTestList = [1.0,1.0]\n",
    "inputTestVect1D = np.array([1.0,1.0])\n",
    "inputTestVect2Drow = np.array([[1.0,1.0]])\n",
    "inputTestVect2Dcol = np.array([[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0]])\n",
    "#initialization from vector\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "neuron = Neuron(vector,identity)\n",
    "#forward pass\n",
    "print(neuron.forward(inputTestList))\n",
    "print(neuron.forward(inputTestVect1D))\n",
    "print(neuron.forward(inputTestVect2Drow))\n",
    "print(neuron.forward(inputTestVect2Dcol))\n",
    "print(neuron.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7a43849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[ 6.5, 12. ]]), array([[ 6.5, 12. ]])]\n"
     ]
    }
   ],
   "source": [
    "#inputs\n",
    "inputTestList = [1.0,1.0]\n",
    "inputTestVect1D = np.array([1.0,1.0])\n",
    "inputTestVect2Drow = np.array([[1.0,1.0]])\n",
    "inputTestVect2Dcol = np.array([[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0]])\n",
    "#initialization from row vector(2D array)\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "vector_row = vector[np.newaxis,:]\n",
    "neuron = Neuron(vector_row,identity)\n",
    "#forward pass\n",
    "print(neuron.forward(inputTestList))\n",
    "print(neuron.forward(inputTestVect1D))\n",
    "print(neuron.forward(inputTestVect2Drow))\n",
    "print(neuron.forward(inputTestVect2Dcol))\n",
    "print(neuron.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6193892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[6.5]]), array([[6.5]])]\n",
      "[array([[ 6.5, 12. ]]), array([[ 6.5, 12. ]])]\n"
     ]
    }
   ],
   "source": [
    "#inputs\n",
    "inputTestList = [1.0,1.0]\n",
    "inputTestVect1D = np.array([1.0,1.0])\n",
    "inputTestVect2Drow = np.array([[1.0,1.0]])\n",
    "inputTestVect2Dcol = np.array([[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0]])\n",
    "#initialization from column vector(2D array)\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "vector_column = vector[:,np.newaxis]\n",
    "neuron = Neuron(vector_column,identity)\n",
    "#forward pass\n",
    "print(neuron.forward(inputTestList))\n",
    "print(neuron.forward(inputTestVect1D))\n",
    "print(neuron.forward(inputTestVect2Drow))\n",
    "print(neuron.forward(inputTestVect2Dcol))\n",
    "print(neuron.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b62878a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for: no function given as activation function\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for activation function initialization. Given variable is not a function and thus can not be used as activation function.\n",
      "Test for: not vector given for weights initialization (2 dim)\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given variable is not an vector (not column or row vector in 2 dim), so it is unsuitable for neuron weight initialization.\n",
      "Test for: not vector given for weights initialization (higher than 2 dim)\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given variable is not an vector (due to more than 2 dim), so it is unsuitable for neuron weight initialization.\n",
      "Test for: wrong weights given for initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given values are not a rational numbers and thus can not be used as weight values.\n",
      "Test for: wrong var type given in list for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Values given in list are not  numbers and thus can not be used as weight values.\n",
      "Test for: input propagation (forward pass) - inproper dimension of input\n",
      "Correct errors was caught. Error: Given array is of size not supported by implementation. Supported dimensions: 1,2.\n",
      "Test for: input propagation (forward pass) - wrong value types in input: they are not rational numbers\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Given values are not a rational numbers and thus can not be used to get output from neuron.\n",
      "Test for: input propagation (forward pass) - given variable is of not supported type for list\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Values given in list are not numbers and thus can not be used as input to neuron.\n",
      "Test for: input propagation (forward pass) - given variable is of not supported type\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Not supported data type given.\n",
      "Test for: input propagation (forward pass) - given input is too small to match neuron dimensions\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Input does not match network, i.e. matrix multiplication cannot be done due to mismatch of dimensions.\n",
      "Test for: input propagation (forward pass) - given input is too small to match neuron dimensions\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Input does not match network, i.e. matrix multiplication cannot be done due to mismatch of dimensions.\n"
     ]
    }
   ],
   "source": [
    "#error messages testing\n",
    "print(\"Test for: no function given as activation function\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    errorNeuron = Neuron(vector,1)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not vector given for weights initialization (2 dim)\")\n",
    "try:\n",
    "    vector = np.array([[1.0,2.0,3.5],[1.0,2.0,3.5]])\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not vector given for weights initialization (higher than 2 dim)\")\n",
    "try:\n",
    "    vector = np.array([[[1.0,2.0,3.5],[1.0,2.0,3.5]],[[1.0,2.0,3.5],[1.0,2.0,3.5]]])\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong weights given for initialization\")\n",
    "try:\n",
    "    vector = np.array([\"1.0\",\"2.0\",\"3.5\"])\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong var type given in list for weight initialization\")\n",
    "try:\n",
    "    vector = [\"as\",\"2.0\",\"3.5\"]\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - inproper dimension of input\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = np.array([[[1.0,1.0],[1.0,1.0]],[[1.0,1.0],[1.0,1.0]]]) \n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedArrayDimGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - wrong value types in input: they are not rational numbers\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = np.array([1.0 + 3j,1.0]) \n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given variable is of not supported type for list\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = [\"a\",\"1.0\"]\n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given variable is of not supported type\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = \"a\"\n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given input is too small to match neuron dimensions\")\n",
    "try:\n",
    "    #wrong input (too small)\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    neuronTest = Neuron(vector,identity)\n",
    "    inputTestErrorSmall = np.array([1.0])\n",
    "    neuronTest.forward(inputTestErrorSmall)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given input is too small to match neuron dimensions\")\n",
    "try:\n",
    "    #wrong input (too big)\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    neuronTest = Neuron(vector,identity)\n",
    "    inputTestErrorBig = np.array([[1.0],[1.0],[1.0],[1.0]])\n",
    "    neuronTest.forward(inputTestErrorBig)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68632b0b",
   "metadata": {},
   "source": [
    "Layer class implementation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61504054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.43321761 -0.39133967  0.02218713  0.0313213   0.6934288   0.30996487]\n",
      " [-0.11152912 -0.70523287 -0.77345744 -0.20196702  0.1988356   0.65243125]\n",
      " [ 0.80787798 -0.73697185 -0.77146234 -0.53531642 -0.53482409 -0.25597751]\n",
      " [-0.78927112 -0.13352324  0.615267    0.4524414  -0.15706959 -0.27352318]]\n",
      "[<function identity at 0x0000017F124FA160>, <function identity at 0x0000017F124FA160>, <function identity at 0x0000017F124FA160>, <function identity at 0x0000017F124FA160>]\n",
      "[array([[ 1.09878005],\n",
      "       [-0.9409196 ],\n",
      "       [-2.02667423],\n",
      "       [-0.28567874]]), array([[ 1.09878005],\n",
      "       [-0.9409196 ],\n",
      "       [-2.02667423],\n",
      "       [-0.28567874]])]\n",
      "[array([[ 1.09878005],\n",
      "       [-0.9409196 ],\n",
      "       [-2.02667423],\n",
      "       [-0.28567874]]), array([[ 1.09878005],\n",
      "       [-0.9409196 ],\n",
      "       [-2.02667423],\n",
      "       [-0.28567874]])]\n",
      "[array([[ 1.09878005],\n",
      "       [-0.9409196 ],\n",
      "       [-2.02667423],\n",
      "       [-0.28567874]]), array([[ 1.09878005],\n",
      "       [-0.9409196 ],\n",
      "       [-2.02667423],\n",
      "       [-0.28567874]])]\n",
      "[array([[ 1.09878005],\n",
      "       [-0.9409196 ],\n",
      "       [-2.02667423],\n",
      "       [-0.28567874]]), array([[ 1.09878005],\n",
      "       [-0.9409196 ],\n",
      "       [-2.02667423],\n",
      "       [-0.28567874]])]\n",
      "[array([[ 1.09878005,  1.76434249],\n",
      "       [-0.9409196 , -1.77031008],\n",
      "       [-2.02667423, -4.86122645],\n",
      "       [-0.28567874,  0.21791364]]), array([[ 1.09878005,  1.76434249],\n",
      "       [-0.9409196 , -1.77031008],\n",
      "       [-2.02667423, -4.86122645],\n",
      "       [-0.28567874,  0.21791364]])]\n"
     ]
    }
   ],
   "source": [
    "#Input data for input propagation (forward pass)\n",
    "inputTestList = [1.0,1.0,1.0,1.0,1.0]\n",
    "inputTestVect1D = np.array([1.0,1.0,1.0,1.0,1.0])\n",
    "inputTestVect2Drow = np.array([[1.0,1.0,1.0,1.0,1.0]])\n",
    "inputTestVect2Dcol = np.array([[1.0],[1.0],[1.0],[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "#initialization by number of dim in vector\n",
    "dim_layer = np.array([4,5])\n",
    "testLayer = Layer(dim_layer,identity,method_ini=\"Random\")\n",
    "#forward pass\n",
    "print(testLayer.forward(inputTestList))\n",
    "print(testLayer.forward(inputTestVect1D))\n",
    "print(testLayer.forward(inputTestVect2Drow))\n",
    "print(testLayer.forward(inputTestVect2Dcol))\n",
    "print(testLayer.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637ade70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8061142  -0.12231126 -0.33229773 -0.60637171  0.08254818  0.35686078]\n",
      " [-0.61314214  0.70452086  0.03788413  0.32575421 -0.15947243 -0.02173008]\n",
      " [ 0.33347566 -0.44683947  0.57252151  0.22420844 -0.44150839 -0.20875436]\n",
      " [-0.65070032  0.78306672 -0.50197369  0.37594698  0.39965875 -0.27763373]]\n",
      "[<function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>]\n",
      "[array([[0.18454246],\n",
      "       [0.27381456],\n",
      "       [0.03310339],\n",
      "       [0.12836472]]), array([[0.18454246],\n",
      "       [0.27381456],\n",
      "       [0.03310339],\n",
      "       [0.12836472]])]\n",
      "[array([[0.18454246],\n",
      "       [0.27381456],\n",
      "       [0.03310339],\n",
      "       [0.12836472]]), array([[0.18454246],\n",
      "       [0.27381456],\n",
      "       [0.03310339],\n",
      "       [0.12836472]])]\n",
      "[array([[0.18454246],\n",
      "       [0.27381456],\n",
      "       [0.03310339],\n",
      "       [0.12836472]]), array([[0.18454246],\n",
      "       [0.27381456],\n",
      "       [0.03310339],\n",
      "       [0.12836472]])]\n",
      "[array([[ 0.18454246, -0.43702928],\n",
      "       [ 0.27381456,  1.16077125],\n",
      "       [ 0.03310339, -0.26726888],\n",
      "       [ 0.12836472,  0.90742976]]), array([[ 0.18454246, -0.43702928],\n",
      "       [ 0.27381456,  1.16077125],\n",
      "       [ 0.03310339, -0.26726888],\n",
      "       [ 0.12836472,  0.90742976]])]\n"
     ]
    }
   ],
   "source": [
    "#Input data for input propagation (forward pass)\n",
    "inputTestList = [1.0,1.0,1.0,1.0,1.0]\n",
    "inputTestVect1D = np.array([1.0,1.0,1.0,1.0,1.0])\n",
    "inputTestVect2Drow = np.array([[1.0,1.0,1.0,1.0,1.0]])\n",
    "inputTestVect2Dcol = np.array([[1.0],[1.0],[1.0],[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "#initialization by number of dim in list\n",
    "dim_layer = [4,5]\n",
    "testLayer = Layer(dim_layer,identity,method_ini=\"Random\")\n",
    "#forward pass\n",
    "print(testLayer.forward(inputTestList))\n",
    "print(testLayer.forward(inputTestVect1D))\n",
    "print(testLayer.forward(inputTestVect2Drow))\n",
    "print(testLayer.forward(inputTestVect2Dcol))\n",
    "print(testLayer.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ae9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -4.  -4.   3.   3.   3. ]\n",
      " [-1.  -4.   3.5  3.5  3.5  3. ]\n",
      " [ 2.  -4.  -2.5  3.   2.2  3. ]]\n",
      "[<function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>]\n",
      "[array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]]), array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]])]\n",
      "[array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]]), array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]])]\n",
      "[array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]]), array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]])]\n",
      "[array([[ 2. ,  3. ],\n",
      "       [ 8.5, 18. ],\n",
      "       [ 3.7,  5.4]]), array([[ 2. ,  3. ],\n",
      "       [ 8.5, 18. ],\n",
      "       [ 3.7,  5.4]])]\n"
     ]
    }
   ],
   "source": [
    "#Input data for input propagation (forward pass)\n",
    "inputTestList = [1.0,1.0,1.0,1.0,1.0]\n",
    "inputTestVect1D = np.array([1.0,1.0,1.0,1.0,1.0])\n",
    "inputTestVect2Drow = np.array([[1.0,1.0,1.0,1.0,1.0]])\n",
    "inputTestVect2Dcol = np.array([[1.0],[1.0],[1.0],[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "#initialization by giving weight array\n",
    "weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "testLayer = Layer(weights,identity,method_ini=\"Random\")\n",
    "#forward pass\n",
    "print(testLayer.forward(inputTestList))\n",
    "print(testLayer.forward(inputTestVect1D))\n",
    "print(testLayer.forward(inputTestVect2Drow))\n",
    "print(testLayer.forward(inputTestVect2Dcol))\n",
    "print(testLayer.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7632900b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -4.  -4.   3.   3.   3. ]\n",
      " [-1.  -4.   3.5  3.5  3.5  3. ]\n",
      " [ 2.  -4.  -2.5  3.   2.2  3. ]]\n",
      "[<function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>]\n",
      "[array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]]), array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]])]\n",
      "[array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]]), array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]])]\n",
      "[array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]]), array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]])]\n",
      "[array([[ 2. ,  3. ],\n",
      "       [ 8.5, 18. ],\n",
      "       [ 3.7,  5.4]]), array([[ 2. ,  3. ],\n",
      "       [ 8.5, 18. ],\n",
      "       [ 3.7,  5.4]])]\n"
     ]
    }
   ],
   "source": [
    "#Input data for input propagation (forward pass)\n",
    "inputTestList = [1.0,1.0,1.0,1.0,1.0]\n",
    "inputTestVect1D = np.array([1.0,1.0,1.0,1.0,1.0])\n",
    "inputTestVect2Drow = np.array([[1.0,1.0,1.0,1.0,1.0]])\n",
    "inputTestVect2Dcol = np.array([[1.0],[1.0],[1.0],[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "#initialization by giving weight array and function (single) from list\n",
    "weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "testLayer = Layer(weights,[identity],method_ini=\"Random\")\n",
    "#forward pass\n",
    "print(testLayer.forward(inputTestList))\n",
    "print(testLayer.forward(inputTestVect1D))\n",
    "print(testLayer.forward(inputTestVect2Drow))\n",
    "print(testLayer.forward(inputTestVect2Dcol))\n",
    "print(testLayer.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c55d285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -4.  -4.   3.   3.   3. ]\n",
      " [-1.  -4.   3.5  3.5  3.5  3. ]\n",
      " [ 2.  -4.  -2.5  3.   2.2  3. ]]\n",
      "[<function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>]\n",
      "[array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]]), array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]])]\n",
      "[array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]]), array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]])]\n",
      "[array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]]), array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]])]\n",
      "[array([[ 2. ,  3. ],\n",
      "       [ 8.5, 18. ],\n",
      "       [ 3.7,  5.4]]), array([[ 2. ,  3. ],\n",
      "       [ 8.5, 18. ],\n",
      "       [ 3.7,  5.4]])]\n"
     ]
    }
   ],
   "source": [
    "#Input data for input propagation (forward pass)\n",
    "inputTestList = [1.0,1.0,1.0,1.0,1.0]\n",
    "inputTestVect1D = np.array([1.0,1.0,1.0,1.0,1.0])\n",
    "inputTestVect2Drow = np.array([[1.0,1.0,1.0,1.0,1.0]])\n",
    "inputTestVect2Dcol = np.array([[1.0],[1.0],[1.0],[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "#initialization by giving weight array and identity function (mutliple same) from list\n",
    "weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "activation_functions = [identity,identity,identity]\n",
    "testLayer = Layer(weights,activation_functions,method_ini=\"Random\")\n",
    "#forward pass\n",
    "print(testLayer.forward(inputTestList))\n",
    "print(testLayer.forward(inputTestVect1D))\n",
    "print(testLayer.forward(inputTestVect2Drow))\n",
    "print(testLayer.forward(inputTestVect2Dcol))\n",
    "print(testLayer.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5c528d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]]), array([[0.88079708],\n",
      "       [8.5       ],\n",
      "       [3.7       ]])]\n",
      "[array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]]), array([[0.88079708],\n",
      "       [8.5       ],\n",
      "       [3.7       ]])]\n",
      "[array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]]), array([[0.88079708],\n",
      "       [8.5       ],\n",
      "       [3.7       ]])]\n",
      "[array([[2. ],\n",
      "       [8.5],\n",
      "       [3.7]]), array([[0.88079708],\n",
      "       [8.5       ],\n",
      "       [3.7       ]])]\n",
      "[array([[ 2. ,  3. ],\n",
      "       [ 8.5, 18. ],\n",
      "       [ 3.7,  5.4]]), array([[ 0.88079708,  0.95257413],\n",
      "       [ 8.5       , 18.        ],\n",
      "       [ 3.7       ,  5.4       ]])]\n"
     ]
    }
   ],
   "source": [
    "#Input data for input propagation (forward pass)\n",
    "inputTestList = [1.0,1.0,1.0,1.0,1.0]\n",
    "inputTestVect1D = np.array([1.0,1.0,1.0,1.0,1.0])\n",
    "inputTestVect2Drow = np.array([[1.0,1.0,1.0,1.0,1.0]])\n",
    "inputTestVect2Dcol = np.array([[1.0],[1.0],[1.0],[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "#initialization by giving weight array and identity function (mutliple different) from list\n",
    "weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "activation_functions = [sigmoid,relu,leaky_relu]\n",
    "testLayer = Layer(weights,activation_functions)\n",
    "#forward pass\n",
    "print(testLayer.forward(inputTestList))\n",
    "print(testLayer.forward(inputTestVect1D))\n",
    "print(testLayer.forward(inputTestVect2Drow))\n",
    "print(testLayer.forward(inputTestVect2Dcol))\n",
    "print(testLayer.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "140d6345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for: wrong var type (not number) given in list for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given values are not integers and thus can not represent of layer weights matrix.\n",
      "Test for: wrong var type given (number, but no int) in list for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given values are not integers and thus can not represent of layer weights matrix.\n",
      "Test for: wrong var type (not number) given in 1D array for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given values are not integers and thus can not represent of layer weights matrix.\n",
      "Test for: wrong var type given (number, but no int) in 1D array for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given values are not integers and thus can not represent of layer weights matrix.\n",
      "Test for: wrong dimensions of given 1D array for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. In this implementation initialization by vector (1 dim) is only supported for dimensions to initialize. As there are only 2 dimensions to initialize layer any other are unsuitable and raise error due to ambiguity\n",
      "Test for: not rational numbers given in 2D array for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given values are not a rational numbers and thus can not be used as weight values.\n",
      "Test for: not enough information given in 2D array for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Given array have insuffiecient information to represent weights of layer.\n",
      "Test for: bigger than 2D was given for array for weight initialization\n",
      "Correct errors was caught. Error: Given array is of size not supported by implementation. Supported dimensions: 1,2.\n",
      "Test for: not supported data type given for array for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Not supported data type given.\n",
      "Test for: not supported data type given for array for weight initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for weights initialization. Not supported data type given.\n",
      "Test for: not compatible amount of activation functions given to the amount of neurons for activation function initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for activation functions initialization. Given activation functions number does not match number of neurons in layer\n",
      "Test for: not activation function given (inside list) for activation function initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for activation functions initialization. Given variable is not function\n",
      "Test for: not activation function given (standalone) for activation function initialization\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for activation functions initialization. Not supported data type given.\n",
      "Test for: input propagation, too much dimensions in input\n",
      "Correct errors was caught. Error: Given array is of size not supported by implementation. Supported dimensions: 1,2.\n",
      "Test for: input propagation, complex input\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Given values are not a rational numbers and thus can not be used to get output from  layer neurons.\n",
      "Test for: input propagation, wrong data type of input\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Not supported data type given.\n",
      "Test for: input propagation, wrong data type of input in list\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Values given in list are not numbers and thus can not be used as input to neuron.\n",
      "Test for: input propagation, input does not match layer neurons\n",
      "Correct errors was caught. Error: Given input is not supported by implementation for input propagation. Input does not match network, i.e. matrix multiplication cannot be done due to mismatch of dimensions.\n"
     ]
    }
   ],
   "source": [
    "#error messages testing\n",
    "print(\"Test for: wrong var type (not number) given in list for weight initialization\")\n",
    "try:\n",
    "    vector = [\"as\",\"2.0\"]\n",
    "    testLayer = Layer(vector,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong var type given (number, but no int) in list for weight initialization\")\n",
    "try:\n",
    "    vector = [1,2.3]\n",
    "    testLayer = Layer(vector,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong var type (not number) given in 1D array for weight initialization\")\n",
    "try:\n",
    "    vector = np.array([\"as\",\"2.0\"])\n",
    "    testLayer = Layer(vector,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong var type given (number, but no int) in 1D array for weight initialization\")\n",
    "try:\n",
    "    vector = np.array([1,2.3])\n",
    "    testLayer = Layer(vector,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong dimensions of given 1D array for weight initialization\")\n",
    "try:\n",
    "    vector = np.array([1,2,1,1,2])\n",
    "    testLayer = Layer(vector,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not rational numbers given in 2D array for weight initialization\")\n",
    "try:\n",
    "    weights = np.array([[1.0 + 4j,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    testLayer = Layer(weights,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not enough information given in 2D array for weight initialization\")\n",
    "try:\n",
    "    weights = np.array([[]])\n",
    "    testLayer = Layer(weights,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: bigger than 2D was given for array for weight initialization\")\n",
    "try:\n",
    "    weights = np.array([[[2]]])\n",
    "    testLayer = Layer(weights,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedArrayDimGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not supported data type given for array for weight initialization\")\n",
    "try:\n",
    "    weights = \"hehe\"\n",
    "    testLayer = Layer(weights,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not supported data type given for array for weight initialization\")\n",
    "try:\n",
    "    weights = \"hehe\"\n",
    "    testLayer = Layer(weights,identity,method_ini=\"Random\")   \n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not compatible amount of activation functions given to the amount of neurons for activation function initialization\")\n",
    "try:\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = [sigmoid,relu,leaky_relu,leaky_relu]\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not activation function given (inside list) for activation function initialization\")\n",
    "try:\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = [sigmoid,1,leaky_relu]\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not activation function given (standalone) for activation function initialization\")\n",
    "try:\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = 1\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation, too much dimensions in input\")\n",
    "try:\n",
    "    #Input data for input propagation (forward pass)\n",
    "    inputTestArray = np.array([[[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]],[[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]]])\n",
    "    #model ini\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = [sigmoid,sigmoid,leaky_relu]\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "    #forward pass test\n",
    "    testLayer.forward(inputTestArray)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedArrayDimGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation, complex input\")\n",
    "try:\n",
    "    #Input data for input propagation (forward pass)\n",
    "    inputTestVect = np.array([[1.0 + 3j],[1.0],[1.0],[1.0],[1.0]])\n",
    "    #model ini\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = [sigmoid,sigmoid,leaky_relu]\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "    #forward pass test\n",
    "    testLayer.forward(inputTestVect)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation, wrong data type of input\")\n",
    "try:\n",
    "    #Input data for input propagation (forward pass)\n",
    "    inputTestVect = \"sda\"\n",
    "    #model ini\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = [sigmoid,sigmoid,leaky_relu]\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "    #forward pass test\n",
    "    testLayer.forward(inputTestVect)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation, wrong data type of input in list\")\n",
    "try:\n",
    "    #Input data for input propagation (forward pass)\n",
    "    inputTestList =[\"a\",1.0,1.0,1.0,1.0]\n",
    "    inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "    #model ini\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = [sigmoid,sigmoid,leaky_relu]\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "    #forward pass test\n",
    "    testLayer.forward(inputTestList)\n",
    "    testLayer.forward(inputTestArray)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation, input does not match layer neurons\")\n",
    "try:\n",
    "    #Input data for input propagation (forward pass)\n",
    "    inputTestList = [1.0,1.0,1.0,1.0,1.0,1.0,1.0]\n",
    "    #model ini\n",
    "    weights = np.array([[1.0,-4.0,-4.0,3.0,3.0,3.0],[-1.0,-4.0,3.5,3.5,3.5,3.0],[2.0,-4.0,-2.5,3.0,2.2,3.0]])\n",
    "    activation_functions = [sigmoid,sigmoid,leaky_relu]\n",
    "    testLayer = Layer(weights,activation_functions)\n",
    "    #forward pass test\n",
    "    testLayer.forward(inputTestList)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0fad2d",
   "metadata": {},
   "source": [
    "FNN class implementation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "000a08cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.63714809 -0.73392543 -0.01535404  0.17902251 -0.61209244 -0.0783883 ]\n",
      " [-0.49911025  0.37424343  0.43252964  0.44397739  0.51112557 -0.59471892]\n",
      " [-0.33478931  0.38055053 -0.44882977 -0.69722032  0.26978059  0.74719579]\n",
      " [ 0.38820814  0.72544925  0.4984846   0.09575951  0.60509861 -0.45976635]\n",
      " [-0.14857648 -0.50928417  0.16746759 -0.0994577  -0.44207178 -0.56924469]]\n",
      "[[-0.76569876  0.59931611 -0.41566795  0.05623372  0.4210207  -0.05758078]\n",
      " [ 0.18245407  0.80641694  0.85204582  0.68374839  0.61261822 -0.05860781]\n",
      " [ 0.56933763 -0.5217913  -0.73851698 -0.47403047 -0.59245796 -0.190516  ]]\n",
      "[[-0.10343311 -0.60003859 -0.68151337 -0.61293706]\n",
      " [-0.74181012  0.20437635 -0.82061213  0.18746547]]\n",
      "[[-0.52445732 -1.00371325 -0.85736644]]\n",
      "[<function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>]\n",
      "[<function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>]\n",
      "[<function identity at 0x0000017F409949A0>, <function identity at 0x0000017F409949A0>]\n",
      "[<function identity at 0x0000017F409949A0>]\n",
      "[[array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]]), array([[-1.89788578],\n",
      "       [ 0.66804685],\n",
      "       [-0.08331249],\n",
      "       [ 1.85323377],\n",
      "       [-1.60116722]]), array([[-1.31305669],\n",
      "       [ 0.39337426],\n",
      "       [ 0.31285149]]), array([[ 0.22460348],\n",
      "       [-1.27432668]]), array([[0.34267013]])], [array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]]), array([[-1.89788578],\n",
      "       [ 0.66804685],\n",
      "       [-0.08331249],\n",
      "       [ 1.85323377],\n",
      "       [-1.60116722]]), array([[-1.31305669],\n",
      "       [ 0.39337426],\n",
      "       [ 0.31285149]]), array([[ 0.22460348],\n",
      "       [-1.27432668]]), array([[0.34267013]])]]\n",
      "[[array([[1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.]]), array([[-1.89788578, -3.15862347],\n",
      "       [ 0.66804685,  1.83520395],\n",
      "       [-0.08331249,  0.16816434],\n",
      "       [ 1.85323377,  3.31825941],\n",
      "       [-1.60116722, -3.05375797]]), array([[-1.31305669, -1.839198  ],\n",
      "       [ 0.39337426,  1.5257468 ],\n",
      "       [ 0.31285149, -0.60170389]]), array([[ 0.22460348,  0.32914643],\n",
      "       [-1.27432668, -2.48254372]]), array([[0.34267013, 1.27362373]])], [array([[1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.],\n",
      "       [1., 2.]]), array([[-1.89788578, -3.15862347],\n",
      "       [ 0.66804685,  1.83520395],\n",
      "       [-0.08331249,  0.16816434],\n",
      "       [ 1.85323377,  3.31825941],\n",
      "       [-1.60116722, -3.05375797]]), array([[-1.31305669, -1.839198  ],\n",
      "       [ 0.39337426,  1.5257468 ],\n",
      "       [ 0.31285149, -0.60170389]]), array([[ 0.22460348,  0.32914643],\n",
      "       [-1.27432668, -2.48254372]]), array([[0.34267013, 1.27362373]])]]\n"
     ]
    }
   ],
   "source": [
    "#initialization by number of dim in vector\n",
    "dim_layer = np.array([5,5,3,2,1])\n",
    "testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "print(testNet.weights_list[0])\n",
    "print(testNet.weights_list[1])\n",
    "print(testNet.weights_list[2])\n",
    "print(testNet.weights_list[3])\n",
    "print(testNet.activ_functions_list[0])\n",
    "print(testNet.activ_functions_list[1])\n",
    "print(testNet.activ_functions_list[2])\n",
    "print(testNet.activ_functions_list[3])\n",
    "#forward test pass\n",
    "inputTestVect = np.array([[1.0],[1.0],[1.0],[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "\n",
    "print(testNet.forward(inputTestVect))\n",
    "print(testNet.forward(inputTestArray))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "277b56ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for: not supported input for weights\n",
      "Correct errors was caught. Error:  Given input is not supported by implementation for weights initialization. \n",
      "Test for: array of not supported dimension\n",
      "Correct errors was caught. Error:  Given array is of size not supported by implementation. Supported dimensions: 1.\n",
      "Test for: given numbers are not integers\n",
      "Correct errors was caught. Error:  Given input is not supported by implementation for weights initialization. Given values in vector must be integers to properly represent number of neurons in layers\n",
      "Test for: not enough numbers given. Minimally required input and output layers cannot be created\n",
      "Correct errors was caught. Error:  Given input is not supported by implementation for weights initialization. At least two numbers are needed for FNN creation: FNN needs at least input and output layer.\n"
     ]
    }
   ],
   "source": [
    "#error messages testing\n",
    "print(\"Test for: not supported input for weights\")\n",
    "try:\n",
    "    dim_layer = \"[5,5,3,2,1]\"\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: array of not supported dimension\")\n",
    "try:\n",
    "    dim_layer = np.array([[5,5,3,2,1],[5,5,3,2,1]])\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedArrayDimGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: given numbers are not integers\")\n",
    "try:\n",
    "    dim_layer = np.array([5,5,3.1,2,1])\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not enough numbers given. Minimally required input and output layers cannot be created\")\n",
    "try:\n",
    "    dim_layer = np.array([5])\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6380a84d",
   "metadata": {},
   "source": [
    "Reload Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd529b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules reloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Reload order:\n",
    "modules_in_order = [\n",
    "    \"ActivFunctions\",\n",
    "    \"SuppFunctions\",\n",
    "    \"InitFunctions\",\n",
    "    \"Layer\",\n",
    "    \"FNN\",\n",
    "    \"TrainingFunctions\"\n",
    "]\n",
    "\n",
    "for m in modules_in_order:\n",
    "    if m in sys.modules:\n",
    "        importlib.reload(sys.modules[m])\n",
    "    else:\n",
    "        globals()[m] = importlib.import_module(m)\n",
    "\n",
    "print(\"All modules reloaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7120a838",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c07c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FNN import FNN\n",
    "from TrainingFunctions import backwards\n",
    "from LossFunctions import MeanSquaredErrorDerivative\n",
    "\n",
    "# Activations\n",
    "from ActivFunctions import identity, sigmoid, tanh, relu, leaky_relu\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8d9cbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Single-Layer Network Gradient ===\n",
      "\n",
      "Gradient matrix for single layer:\n",
      "[[-0.28651963 -0.28651963 -0.28651963 -0.28651963 -0.28651963]\n",
      " [-0.20215458 -0.20215458 -0.20215458 -0.20215458 -0.20215458]\n",
      " [-0.04648601 -0.04648601 -0.04648601 -0.04648601 -0.04648601]\n",
      " [-0.10887373 -0.10887373 -0.10887373 -0.10887373 -0.10887373]\n",
      " [-0.25104898 -0.25104898 -0.25104898 -0.25104898 -0.25104898]]\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Test 1: Single-Layer Network Gradient ===\")\n",
    "\n",
    "dim_layer = np.array([4, 5])   # 4 inputs -> 5 outputs\n",
    "testNet = FNN(dim_layer, identity, method_ini=\"Random\")\n",
    "\n",
    "inputTestVect = np.ones((4, 1))\n",
    "targetVect = 0.5 * np.ones((5, 1))\n",
    "\n",
    "grads = backwards(testNet, inputTestVect, targetVect, MeanSquaredErrorDerivative)\n",
    "\n",
    "print(\"\\nGradient matrix for single layer:\")\n",
    "print(grads[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13580c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 2: Deep 10-Layer Network ===\n",
      "\n",
      "Gradient matrix for layer 0:\n",
      "[[ 0.07727597  0.07727597  0.07727597  0.07727597  0.07727597  0.07727597]\n",
      " [-0.14769014 -0.14769014 -0.14769014 -0.14769014 -0.14769014 -0.14769014]\n",
      " [ 0.17912042  0.17912042  0.17912042  0.17912042  0.17912042  0.17912042]\n",
      " [-0.21438547 -0.21438547 -0.21438547 -0.21438547 -0.21438547 -0.21438547]\n",
      " [-0.04274995 -0.04274995 -0.04274995 -0.04274995 -0.04274995 -0.04274995]\n",
      " [ 0.07400811  0.07400811  0.07400811  0.07400811  0.07400811  0.07400811]\n",
      " [-0.20884372 -0.20884372 -0.20884372 -0.20884372 -0.20884372 -0.20884372]\n",
      " [ 0.09958415  0.09958415  0.09958415  0.09958415  0.09958415  0.09958415]]\n",
      "\n",
      "Gradient matrix for layer 1:\n",
      "[[-0.27736981 -0.30991231  0.06742132  0.12852211 -0.14600172  0.18113258\n",
      "  -0.0411052   0.37446738  0.15747543]\n",
      " [-0.01613784 -0.01803122  0.00392268  0.00747763 -0.00849462  0.0105386\n",
      "  -0.00239157  0.02178714  0.00916218]\n",
      " [-0.20478568 -0.22881222  0.04977802  0.09488952 -0.10779493  0.1337325\n",
      "  -0.0303485   0.27647406  0.11626612]\n",
      " [-0.17975205 -0.20084151  0.043693    0.08328993 -0.09461775  0.11738463\n",
      "  -0.0266386   0.24267702  0.10205339]\n",
      " [-0.18250308 -0.20391531  0.04436171  0.08456465 -0.09606584  0.11918115\n",
      "  -0.0270463   0.24639109  0.10361528]\n",
      " [-0.02618754 -0.02926     0.0063655   0.01213426 -0.01378458  0.01710141\n",
      "  -0.0038809   0.03535489  0.01486785]]\n",
      "\n",
      "Gradient matrix for layer 2:\n",
      "[[-0.06683378 -0.11595721  0.01281198  0.1081952   0.02122789  0.11496218\n",
      "  -0.06320455]\n",
      " [-0.1223788  -0.21232834  0.02345992  0.19811538  0.03887023  0.21050635\n",
      "  -0.11573336]\n",
      " [ 0.08112524  0.14075302 -0.01555164 -0.13133122 -0.02576718 -0.13954522\n",
      "   0.07671996]\n",
      " [ 0.07974331  0.13835538 -0.01528673 -0.12909406 -0.02532825 -0.13716815\n",
      "   0.07541308]\n",
      " [-0.22574846 -0.39167564  0.0432758   0.36545742  0.07170272  0.38831467\n",
      "  -0.21348982]\n",
      " [ 0.07034867  0.12205559 -0.01348578 -0.11388536 -0.0223443  -0.12100823\n",
      "   0.06652859]\n",
      " [ 0.07649289  0.13271586 -0.01466363 -0.12383205 -0.02429584 -0.13157703\n",
      "   0.07233916]]\n",
      "\n",
      "Gradient matrix for layer 3:\n",
      "[[ 0.00967892  0.00204253 -0.0123297  -0.01300088 -0.00141191 -0.00120679\n",
      "   0.00944701  0.00341665]\n",
      " [-0.19320469 -0.04077175  0.2461179   0.25951573  0.02818378  0.02408922\n",
      "  -0.18857554 -0.06820111]\n",
      " [ 0.15437089  0.0325767  -0.19664863 -0.20735353 -0.02251889 -0.01924733\n",
      "   0.15067219  0.05449281]\n",
      " [-0.28817687 -0.06081361  0.36710022  0.38708393  0.04203786  0.03593058\n",
      "  -0.2812722  -0.10172622]\n",
      " [-0.18637003 -0.03932944  0.23741143  0.25033531  0.02718677  0.02323706\n",
      "  -0.18190464 -0.06578848]]\n",
      "\n",
      "Gradient matrix for layer 4:\n",
      "[[-0.26088575  0.19238134  0.29589181 -0.20154249 -0.20601477  0.4050081 ]\n",
      " [ 0.16083068 -0.11859913 -0.1824112   0.12424679  0.12700385 -0.24967914]\n",
      " [-0.08586617  0.06331909  0.09738783 -0.06633433 -0.0678063   0.13330162]\n",
      " [-0.07333103  0.05407548  0.08317071 -0.05665054 -0.05790763  0.11384165]\n",
      " [-0.07131712  0.05259039  0.08088657 -0.05509473 -0.0563173   0.11071518]\n",
      " [-0.06228532  0.0459302   0.07064287 -0.04811738 -0.04918512  0.0966939 ]\n",
      " [ 0.01045351 -0.00770859 -0.01185618  0.00807567  0.00825487 -0.01622839]\n",
      " [ 0.12778768 -0.09423269 -0.14493444  0.09872003  0.10091065 -0.19838204]\n",
      " [-0.15067061  0.11110693  0.17088784 -0.11639782 -0.11898071  0.2339063 ]]\n",
      "\n",
      "Gradient matrix for layer 5:\n",
      "[[-0.0362097   0.03889643 -0.01114447  0.03386965 -0.05904207  0.02049957\n",
      "   0.03194414 -0.07829945  0.0260395   0.05577162]\n",
      " [-0.10436462  0.11210839 -0.03212092  0.09762008 -0.17017274  0.05908444\n",
      "   0.09207029 -0.2256769   0.07505179  0.16074655]\n",
      " [-0.23753213  0.25515683 -0.07310668  0.22218167 -0.38731032  0.13447521\n",
      "   0.20955045 -0.51363685  0.17081661  0.36585646]\n",
      " [-0.02442123  0.02623327 -0.00751627  0.02284302 -0.03982028  0.01382571\n",
      "   0.02154437 -0.0528082   0.01756205  0.03761456]]\n",
      "\n",
      "Gradient matrix for layer 6:\n",
      "[[-0.3714926   0.17792978  0.18043575  0.5936211  -0.33911936]\n",
      " [-0.23308607  0.11163871  0.11321103  0.37245643 -0.21277408]\n",
      " [-0.11732046  0.05619171  0.05698312  0.1874705  -0.10709672]]\n",
      "\n",
      "Gradient matrix for layer 7:\n",
      "[[-0.44066846  0.80900347  0.20469202  0.20249228]\n",
      " [-0.11942708  0.21925081  0.05547429  0.05487813]]\n",
      "\n",
      "Gradient matrix for layer 8:\n",
      "[[-0.00551267  0.01127264  0.00648209]\n",
      " [-0.3227408   0.65995958  0.37949589]\n",
      " [ 0.13185795 -0.26963099 -0.15504563]\n",
      " [ 0.17540154 -0.35867151 -0.20624651]]\n",
      "\n",
      "Gradient matrix for layer 9:\n",
      "[[ 0.2497353   0.21055784 -0.66307812 -0.43749499  0.51207735]]\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Test 2: Deep 10-Layer Network ===\")\n",
    "\n",
    "dim_layer = np.array([\n",
    "    5, 8, 6, 7, 5, 9, 4, 3, 2, 4, 1\n",
    "])\n",
    "\n",
    "deepNet = FNN(dim_layer, identity, method_ini=\"Random\")\n",
    "\n",
    "inputVect = np.ones((5, 1))\n",
    "targetVect = np.array([[0.7]])\n",
    "\n",
    "grads = backwards(deepNet, inputVect, targetVect, MeanSquaredErrorDerivative)\n",
    "\n",
    "for i, g in enumerate(grads):\n",
    "    print(f\"\\nGradient matrix for layer {i}:\")\n",
    "    print(g)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02452",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
