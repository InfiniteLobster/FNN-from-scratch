{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c419d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FNN import FNN\n",
    "from Layer import Layer\n",
    "from Neuron import Neuron\n",
    "import numpy as np\n",
    "from ActivFunctions import  *\n",
    "from InitFunctions import  *\n",
    "from SuppFunctions import  *\n",
    "from ErrorClasses import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ea47f5",
   "metadata": {},
   "source": [
    "Neuron Class functionality testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f675aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTest = np.array([1.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c9de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero initialization\n",
    "t0NeuronZero = Neuron(2,identity)\n",
    "print(t0NeuronZero.weight_vector.shape)\n",
    "t0NeuronZero.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef7148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random initialization\n",
    "t0NeuronRandom = Neuron(2,identity,method_ini=\"Random\")\n",
    "print(t0NeuronRandom.weight_vector.shape)\n",
    "t0NeuronRandom.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe12c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization from list\n",
    "vector = [1.0,2.0,3.5]\n",
    "print(vector)\n",
    "tNeuron = Neuron(vector,identity)\n",
    "print(tNeuron.weight_vector.shape)\n",
    "tNeuron.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization from vector\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "print(vector)\n",
    "print(vector.shape)\n",
    "t1Neuron = Neuron(vector,identity)\n",
    "print(t1Neuron.weight_vector.shape)\n",
    "t1Neuron.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a43849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization from row vector(2D array)\n",
    "vector_row = vector[np.newaxis,:]\n",
    "print(vector_row)\n",
    "print(vector_row.shape)\n",
    "t2Neuron = Neuron(vector_row,identity)\n",
    "print(t2Neuron.weight_vector.shape)\n",
    "t2Neuron.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6193892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization from column vector(2D array)\n",
    "vector_column = vector[:,np.newaxis]\n",
    "print(vector_column)\n",
    "print(vector_column.shape)\n",
    "t3Neuron = Neuron(vector_column,identity)\n",
    "print(t3Neuron.weight_vector.shape)\n",
    "t3Neuron.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aceccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#array input\n",
    "t0NeuronRandom = Neuron(2,identity,method_ini=\"Random\")\n",
    "inputTest = np.array([[1.0,1.0],[1.0,1.0]])\n",
    "print(inputTest.shape)\n",
    "print(inputTest)\n",
    "print(t0NeuronRandom.weight_vector.shape)\n",
    "t0NeuronRandom.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce592a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list input\n",
    "vector = np.array([1.0,2.0,3.5])\n",
    "t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "inputTest = [\"1.0\",\"1.0\"]\n",
    "t0NeuronRandom.forward(inputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62878a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#error messages testing\n",
    "print(\"Test for: no function given as activation function\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    errorNeuron = Neuron(vector,1)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not vector given for weights initialization (2 dim)\")\n",
    "try:\n",
    "    vector = np.array([[1.0,2.0,3.5],[1.0,2.0,3.5]])\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not vector given for weights initialization (higher than 2 dim)\")\n",
    "try:\n",
    "    vector = np.array([[[1.0,2.0,3.5],[1.0,2.0,3.5]],[[1.0,2.0,3.5],[1.0,2.0,3.5]]])\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong weights given for initialization\")\n",
    "try:\n",
    "    vector = np.array([\"1.0\",\"2.0\",\"3.5\"])\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: wrong var type given in list for weight initialization\")\n",
    "try:\n",
    "    vector = [\"as\",\"2.0\",\"3.5\"]\n",
    "    errorNeuron = Neuron(vector,identity)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - inproper dimension of input\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = np.array([[[1.0,1.0],[1.0,1.0]],[[1.0,1.0],[1.0,1.0]]]) \n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedArrayDimGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - wrong value types in input: they are not rational numbers\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = np.array([1.0 + 3j,1.0]) \n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given variable is of not supported type for list\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = [\"a\",\"1.0\"]\n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given variable is of not supported type\")\n",
    "try:\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    t0NeuronRandom = Neuron(vector,identity,method_ini=\"Random\")\n",
    "    inputTest = \"a\"\n",
    "    t0NeuronRandom.forward(inputTest)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given input is too small to match neuron dimensions\")\n",
    "try:\n",
    "    #wrong input (too small)\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    neuronTest = Neuron(vector,identity)\n",
    "    inputTestErrorSmall = np.array([1.0])\n",
    "    neuronTest.forward(inputTestErrorSmall)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: input propagation (forward pass) - given input is too small to match neuron dimensions\")\n",
    "try:\n",
    "    #wrong input (too big)\n",
    "    vector = np.array([1.0,2.0,3.5])\n",
    "    neuronTest = Neuron(vector,identity)\n",
    "    inputTestErrorBig = np.array([[1.0],[1.0],[1.0],[1.0]])\n",
    "    neuronTest.forward(inputTestErrorBig)\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error:\",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68632b0b",
   "metadata": {},
   "source": [
    "Layer class implementation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61504054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization by number of dim in vector\n",
    "dim_layer = np.array([4,5])\n",
    "testLayer = Layer(dim_layer,identity,method_ini=\"Random\")\n",
    "testLayer.weights_array\n",
    "testLayer.activ_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637ade70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward test pass\n",
    "inputTestVect = np.array([[1.0],[1.0],[1.0],[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "\n",
    "print(testLayer.forward(inputTestVect))\n",
    "print(testLayer.forward(inputTestArray))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0fad2d",
   "metadata": {},
   "source": [
    "FNN class implementation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a08cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization by number of dim in vector\n",
    "dim_layer = np.array([5,5,3,2,1])\n",
    "testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "print(testNet.weights_list[0])\n",
    "print(testNet.weights_list[1])\n",
    "print(testNet.weights_list[2])\n",
    "print(testNet.weights_list[3])\n",
    "print(testNet.activ_functions_list[0])\n",
    "print(testNet.activ_functions_list[1])\n",
    "print(testNet.activ_functions_list[2])\n",
    "print(testNet.activ_functions_list[3])\n",
    "#forward test pass\n",
    "inputTestVect = np.array([[1.0],[1.0],[1.0],[1.0],[1.0]])\n",
    "inputTestArray = np.array([[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0],[1.0,2.0]])\n",
    "\n",
    "print(testNet.forward(inputTestVect))\n",
    "print(testNet.forward(inputTestArray))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#error messages testing\n",
    "print(\"Test for: not supported input for weights\")\n",
    "try:\n",
    "    dim_layer = \"[5,5,3,2,1]\"\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: array of not supported dimension\")\n",
    "try:\n",
    "    dim_layer = np.array([[5,5,3,2,1],[5,5,3,2,1]])\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedArrayDimGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: given numbers are not integers\")\n",
    "try:\n",
    "    dim_layer = np.array([5,5,3.1,2,1])\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")\n",
    "#\n",
    "print(\"Test for: not enough numbers given. Minimally required input and output layers cannot be created\")\n",
    "try:\n",
    "    dim_layer = np.array([5])\n",
    "    testNet = FNN(dim_layer,identity,method_ini=\"Random\")\n",
    "except Exception as error_caught:\n",
    "    if(isinstance(error_caught, NotSupportedInputGiven)):\n",
    "        print(\"Correct errors was caught. Error: \",error_caught)\n",
    "    else:\n",
    "       print(\"Something went wrong: wrong error caught. Error: \", error_caught) \n",
    "else:\n",
    "    print(\"Something went wrong: no error caught\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6380a84d",
   "metadata": {},
   "source": [
    "Reload Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd529b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules reloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Reload order:\n",
    "modules_in_order = [\n",
    "    \"ActivFunctions\",\n",
    "    \"SuppFunctions\",\n",
    "    \"InitFunctions\",\n",
    "    \"Layer\",\n",
    "    \"FNN\",\n",
    "    \"TrainingFunctions\"\n",
    "]\n",
    "\n",
    "for m in modules_in_order:\n",
    "    if m in sys.modules:\n",
    "        importlib.reload(sys.modules[m])\n",
    "    else:\n",
    "        globals()[m] = importlib.import_module(m)\n",
    "\n",
    "print(\"All modules reloaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7120a838",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c07c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FNN import FNN\n",
    "from TrainingFunctions import backwards\n",
    "from LossFunctions import MeanSquaredErrorDerivative\n",
    "\n",
    "# Activations\n",
    "from ActivFunctions import identity, sigmoid, tanh, relu, leaky_relu\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8d9cbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 1: Single-Layer Network Gradient ===\n",
      "\n",
      "Gradient matrix for single layer:\n",
      "[[ 0.18096633  0.18096633  0.18096633  0.18096633  0.18096633]\n",
      " [-0.20739758 -0.20739758 -0.20739758 -0.20739758 -0.20739758]\n",
      " [-0.27906518 -0.27906518 -0.27906518 -0.27906518 -0.27906518]\n",
      " [ 0.0208465   0.0208465   0.0208465   0.0208465   0.0208465 ]\n",
      " [-0.21430231 -0.21430231 -0.21430231 -0.21430231 -0.21430231]]\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Test 1: Single-Layer Network Gradient ===\")\n",
    "\n",
    "dim_layer = np.array([4, 5])   # 4 inputs -> 5 outputs\n",
    "testNet = FNN(dim_layer, identity, method_ini=\"Random\")\n",
    "\n",
    "inputTestVect = np.ones((4, 1))\n",
    "targetVect = 0.5 * np.ones((5, 1))\n",
    "\n",
    "grads = backwards(testNet, inputTestVect, targetVect, MeanSquaredErrorDerivative)\n",
    "\n",
    "print(\"\\nGradient matrix for single layer:\")\n",
    "print(grads[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13580c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test 2: Deep 10-Layer Network ===\n",
      "\n",
      "Gradient matrix for layer 0:\n",
      "[[-0.27870105 -0.27870105 -0.27870105 -0.27870105 -0.27870105 -0.27870105]\n",
      " [-0.11598209 -0.11598209 -0.11598209 -0.11598209 -0.11598209 -0.11598209]\n",
      " [-0.13091222 -0.13091222 -0.13091222 -0.13091222 -0.13091222 -0.13091222]\n",
      " [ 0.13063314  0.13063314  0.13063314  0.13063314  0.13063314  0.13063314]\n",
      " [ 0.00034883  0.00034883  0.00034883  0.00034883  0.00034883  0.00034883]\n",
      " [-0.15887562 -0.15887562 -0.15887562 -0.15887562 -0.15887562 -0.15887562]\n",
      " [ 0.01168297  0.01168297  0.01168297  0.01168297  0.01168297  0.01168297]\n",
      " [-0.12633069 -0.12633069 -0.12633069 -0.12633069 -0.12633069 -0.12633069]]\n",
      "\n",
      "Gradient matrix for layer 1:\n",
      "[[-4.58512351e-01 -1.33903661e-01 -1.11894248e-01 -1.04387429e-01\n",
      "   3.33853544e-01  3.47242206e-02  7.81936346e-02  1.15368556e-01\n",
      "   1.49208635e-01]\n",
      " [-2.11530336e-01 -6.17751872e-02 -5.16213526e-02 -4.81581531e-02\n",
      "   1.54020174e-01  1.60196907e-02  3.60738936e-02  5.32241917e-02\n",
      "   6.88359924e-02]\n",
      " [-7.93230445e-02 -2.31654524e-02 -1.93578043e-02 -1.80591181e-02\n",
      "   5.77569600e-02  6.00732104e-03  1.35275683e-02  1.99588627e-02\n",
      "   2.58132266e-02]\n",
      " [-9.21025046e-04 -2.68975580e-04 -2.24764729e-04 -2.09685599e-04\n",
      "   6.70619831e-04  6.97513966e-05  1.57069479e-04  2.31743657e-04\n",
      "   2.99719058e-04]\n",
      " [-6.29871302e-02 -1.83947222e-02 -1.53712273e-02 -1.43399946e-02\n",
      "   4.58623996e-02  4.77016377e-03  1.07416793e-02  1.58485027e-02\n",
      "   2.04972096e-02]\n",
      " [ 1.05328341e-02  3.07600231e-03  2.57040742e-03  2.39796263e-03\n",
      "  -7.66920236e-03 -7.97676345e-04 -1.79624514e-03 -2.65021838e-03\n",
      "  -3.42758446e-03]]\n",
      "\n",
      "Gradient matrix for layer 2:\n",
      "[[-0.15096342 -0.11523442  0.03631976  0.14707308  0.00314274 -0.14681724\n",
      "   0.08892666]\n",
      " [-0.09725631 -0.07423835  0.02339856  0.09475001  0.00202467 -0.09458519\n",
      "   0.0572899 ]\n",
      " [ 0.12227996  0.09333957 -0.02941891 -0.1191288  -0.00254561  0.11892157\n",
      "  -0.07203035]\n",
      " [-0.15339015 -0.1170868   0.0369036   0.14943727  0.00319325 -0.14917732\n",
      "   0.09035615]\n",
      " [-0.22705992 -0.17332091  0.05462755  0.22120857  0.0047269  -0.22082377\n",
      "   0.13375214]\n",
      " [ 0.27389926  0.20907463 -0.06589646 -0.26684085 -0.005702    0.26637667\n",
      "  -0.16134336]\n",
      " [-0.24542038 -0.18733594  0.05904483  0.23909588  0.00510913 -0.23867996\n",
      "   0.14456757]]\n",
      "\n",
      "Gradient matrix for layer 3:\n",
      "[[ 0.09502866 -0.01387199 -0.00205428 -0.04648627  0.07442841 -0.03082425\n",
      "  -0.0965819  -0.00881303]\n",
      " [-0.0519319   0.00758086  0.00112264  0.02540413 -0.04067413  0.01684504\n",
      "   0.05278072  0.0048162 ]\n",
      " [-0.11295817  0.01648929  0.00244188  0.05525705 -0.08847117  0.03664001\n",
      "   0.11480448  0.01047583]\n",
      " [ 0.50311836 -0.07344368 -0.01087618 -0.24611622  0.39405269 -0.16319549\n",
      "  -0.51134185 -0.04665959]\n",
      " [ 0.17521404 -0.02557721 -0.00378769 -0.08571148  0.13723125 -0.05683383\n",
      "  -0.17807792 -0.01624949]]\n",
      "\n",
      "Gradient matrix for layer 4:\n",
      "[[-1.63883049e-01  4.76184885e-02 -1.88624455e-01 -7.86108288e-02\n",
      "   1.89536898e-02  2.31078101e-02]\n",
      " [ 2.48270336e-01 -7.21383828e-02  2.85751681e-01  1.19089417e-01\n",
      "  -2.87133962e-02 -3.50065720e-02]\n",
      " [ 2.18937276e-01 -6.36152561e-02  2.51990212e-01  1.05019041e-01\n",
      "  -2.53209177e-02 -3.08705568e-02]\n",
      " [ 1.98956751e-01 -5.78096382e-02  2.28993230e-01  9.54348555e-02\n",
      "  -2.30100951e-02 -2.80532663e-02]\n",
      " [-1.99734116e-01  5.80355123e-02 -2.29887953e-01 -9.58077390e-02\n",
      "   2.31000002e-02  2.81628762e-02]\n",
      " [-8.64853702e-02  2.51295215e-02 -9.95420569e-02 -4.14849898e-02\n",
      "   1.00023577e-02  1.21945956e-02]\n",
      " [ 3.68440410e-01 -1.07055461e-01  4.24063818e-01  1.76732164e-01\n",
      "  -4.26115164e-02 -5.19507726e-02]\n",
      " [-1.22616923e-01  3.56280442e-02 -1.41128386e-01 -5.88164423e-02\n",
      "   1.41811073e-02  1.72892106e-02]\n",
      " [-3.29464312e-03  9.57304164e-04 -3.79203502e-03 -1.58036250e-03\n",
      "   3.81037843e-04  4.64550713e-04]]\n",
      "\n",
      "Gradient matrix for layer 5:\n",
      "[[ 0.36396478  0.41478169  0.30156802  0.1545662  -0.41953414 -0.04235245\n",
      "  -0.24556391 -0.04500312  0.44354834 -0.14719337]\n",
      " [-0.0725568  -0.08268721 -0.06011794 -0.03081295  0.08363462  0.00844301\n",
      "   0.04895345  0.00897142 -0.08842188  0.02934317]\n",
      " [-0.10020697 -0.1141979  -0.08302786 -0.04255524  0.11550635  0.0116605\n",
      "   0.06760878  0.01239028 -0.12211795  0.04052535]\n",
      " [ 0.05587448  0.0636757   0.04629557  0.02372841 -0.06440527 -0.00650179\n",
      "  -0.03769803 -0.00690871  0.06809184 -0.02259656]]\n",
      "\n",
      "Gradient matrix for layer 6:\n",
      "[[ 0.36052362 -0.1459801  -0.10612823  0.49517502 -0.09553522]\n",
      " [-0.22059022  0.08931948  0.06493569 -0.30297811  0.05845424]\n",
      " [-0.36489936  0.14775189  0.10741633 -0.50118505  0.09669475]]\n",
      "\n",
      "Gradient matrix for layer 7:\n",
      "[[-0.4122755  -0.32012409 -0.36097512 -0.77194853]\n",
      " [ 0.01511265  0.01173469  0.01323215  0.02829708]]\n",
      "\n",
      "Gradient matrix for layer 8:\n",
      "[[ 0.1636622   0.26179905  0.37564458]\n",
      " [-0.1887131  -0.30187123 -0.43314248]\n",
      " [ 0.01366978  0.02186659  0.03137546]\n",
      " [ 0.22517655  0.36019928  0.51683497]]\n",
      "\n",
      "Gradient matrix for layer 9:\n",
      "[[-0.18243887 -0.67129561  0.0146258  -0.35136911  0.62642166]]\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Test 2: Deep 10-Layer Network ===\")\n",
    "\n",
    "dim_layer = np.array([\n",
    "    5, 8, 6, 7, 5, 9, 4, 3, 2, 4, 1\n",
    "])\n",
    "\n",
    "deepNet = FNN(dim_layer, identity, method_ini=\"Random\")\n",
    "\n",
    "inputVect = np.ones((5, 1))\n",
    "targetVect = np.array([[0.7]])\n",
    "\n",
    "grads = backwards(deepNet, inputVect, targetVect, MeanSquaredErrorDerivative)\n",
    "\n",
    "for i, g in enumerate(grads):\n",
    "    print(f\"\\nGradient matrix for layer {i}:\")\n",
    "    print(g)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
